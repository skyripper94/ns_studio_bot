# lama_integration.py

# ============== –ò–ú–ü–û–†–¢–´ ==============
import os
import logging
import base64
from io import BytesIO

import numpy as np
import cv2
import requests
from PIL import Image, ImageDraw, ImageFont

import openai
import re

logger = logging.getLogger(__name__)

"""
==============================================
–ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø –ë–´–°–¢–†–û–ô –†–£–ß–ù–û–ô –ü–†–ê–í–ö–ò
==============================================
"""

# ============== API –ö–õ–Æ–ß–ò ==============
REPLICATE_API_TOKEN = os.getenv("REPLICATE_API_TOKEN", "").strip()
GOOGLE_VISION_API_KEY = os.getenv("GOOGLE_VISION_API_KEY", "").strip()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()

# ============== REPLICATE / FLUX (INPAINT) ==============
REPLICATE_MODEL = os.getenv("REPLICATE_MODEL", "black-forest-labs/flux-fill-pro").strip()
FLUX_STEPS = int(os.getenv("FLUX_STEPS", "50"))
FLUX_GUIDANCE = float(os.getenv("FLUX_GUIDANCE", "3.5"))
FLUX_OUTPUT_FORMAT = os.getenv("FLUX_OUTPUT_FORMAT", "png")
FLUX_PROMPT_UPSAMPLING = False
REPLICATE_HTTP_TIMEOUT = int(os.getenv("REPLICATE_HTTP_TIMEOUT", "120"))

FORCE_PRESERVE_OUTSIDE_MASK = True

# ============== –¶–í–ï–¢–ê ==============
COLOR_TURQUOISE = (0, 206, 209)    # –±–∏—Ä—é–∑–æ–≤—ã–π —Ü–≤–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
COLOR_WHITE = (255, 255, 255)      # –±–µ–ª—ã–π —Ü–≤–µ—Ç –¥–ª—è –ª–æ–≥–æ –∏ –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∞
COLOR_OUTLINE = (60, 60, 60)       # —Ç–µ–º–Ω–æ-—Å–µ—Ä–∞—è –æ–±–≤–æ–¥–∫–∞ —Ç–µ–∫—Å—Ç–∞

# ============== –†–ê–ó–ú–ï–†–´ –®–†–ò–§–¢–û–í ==============
FONT_SIZE_MODE1 = 48               # –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤ —Ä–µ–∂–∏–º–µ –õ–û–ì–û
FONT_SIZE_MODE2 = 48               # –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤ —Ä–µ–∂–∏–º–µ –¢–ï–ö–°–¢
FONT_SIZE_MODE3_TITLE = 48         # –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤ —Ä–µ–∂–∏–º–µ –ö–û–ù–¢–ï–ù–¢
FONT_SIZE_MODE3_SUBTITLE = 46      # –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤ —Ä–µ–∂–∏–º–µ –ö–û–ù–¢–ï–ù–¢
FONT_SIZE_LOGO = 24                # —Ä–∞–∑–º–µ—Ä @neurostep.media
FONT_SIZE_MIN = 44                 # –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä (–Ω–µ –º–µ–Ω—å—à–µ)

# ============== –û–¢–°–¢–£–ü–´ –ò –†–ê–°–°–¢–û–Ø–ù–ò–Ø ==============
SPACING_BOTTOM_MODE1 = -20         # –æ—Ç—Å—Ç—É–ø —Å–Ω–∏–∑—É –¥–ª—è —Ä–µ–∂–∏–º–∞ 1 (–ª–æ–≥–æ)
SPACING_BOTTOM_MODE2 = -20         # –æ—Ç—Å—Ç—É–ø —Å–Ω–∏–∑—É –¥–ª—è —Ä–µ–∂–∏–º–∞ 2 (+40px –≤—ã—à–µ)
SPACING_BOTTOM_MODE3 = 40          # –æ—Ç—Å—Ç—É–ø —Å–Ω–∏–∑—É –¥–ª—è —Ä–µ–∂–∏–º–∞ 3
SPACING_LOGO_TO_TITLE = 4          # —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç –ª–æ–≥–æ –¥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞
SPACING_TITLE_TO_SUBTITLE = -30    # —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–æ–∫ ‚Üí –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫
LINE_SPACING = -35                 # –º–µ–∂—Å—Ç—Ä–æ—á–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª (—Ä–µ–∂–∏–º 1,3)
LOGO_LINE_LENGTH = 310             # –¥–ª–∏–Ω–∞ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π —É –ª–æ–≥–æ
LOGO_LINE_THICKNESS_PX = 3         # —Ç–æ–ª—â–∏–Ω–∞ –ª–∏–Ω–∏–π —É –ª–æ–≥–æ

# ============== –ú–ê–°–ö–ê / OCR ==============
MASK_BOTTOM_MODE1 = 36
MASK_BOTTOM_MODE2 = 33
MASK_BOTTOM_MODE3 = 30           # % —Å–Ω–∏–∑—É –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è (–º–∞—Å–∫–∞)
OCR_BOTTOM_PERCENT = 32            # % —Å–Ω–∏–∑—É –¥–ª—è OCR —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è

# ============== –ì–†–ê–î–ò–ï–ù–¢ (Instagram-—Å—Ç–∏–ª—å) ==============
GRADIENT_HEIGHT_MODE12 = 55        # % –≤—ã—Å–æ—Ç—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ (—Ä–µ–∂–∏–º 1-2)
GRADIENT_HEIGHT_MODE3 = 40         # % –≤—ã—Å–æ—Ç—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ (—Ä–µ–∂–∏–º 3)
GRADIENT_SOLID_FRACTION = 0.5      # 50% –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ = —Å–ø–ª–æ—à–Ω–æ–π —á–µ—Ä–Ω—ã–π
GRADIENT_TRANSITION_CURVE = 2.2    # –ø–ª–∞–≤–Ω–æ—Å—Ç—å –ø–µ—Ä–µ—Ö–æ–¥–∞ (–≤—ã—à–µ = –º—è–≥—á–µ)
GRADIENT_BLUR_SIGMA = 120          # —Ä–∞–∑–º—ã—Ç–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ (–≤—ã—à–µ = –±–æ–ª—å—à–µ)

# ============== –£–õ–£–ß–®–ï–ù–ò–Ø –ì–†–ê–î–ò–ï–ù–¢–ê ==============
GRADIENT_NOISE_INTENSITY = 10      # —à—É–º –Ω–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–µ (0-20, –ø–ª–µ–Ω–æ—á–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç)

# ============== –ü–û–°–¢–û–ë–†–ê–ë–û–¢–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø ==============
ENHANCE_BRIGHTNESS = 1.05          # —è—Ä–∫–æ—Å—Ç—å (1.0 = –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
ENHANCE_CONTRAST = 1.0             # –∫–æ–Ω—Ç—Ä–∞—Å—Ç (1.0 = –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
ENHANCE_SATURATION = 1.25          # –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å (+25%)
ENHANCE_SHARPNESS = 1.3            # —Ä–µ–∑–∫–æ—Å—Ç—å (+30%)

# ============== –ö–ï–†–ù–ò–ù–ì –¢–ï–ö–°–¢–ê ==============
LETTER_SPACING_PX = 4              # —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –±—É–∫–≤–∞–º–∏ (–ø—Ä–µ–º–∏—É–º —ç—Ñ—Ñ–µ–∫—Ç)

# ============== –£–õ–£–ß–®–ï–ù–ò–Ø –¢–ï–ö–°–¢–ê ==============
TEXT_GRAIN_INTENSITY = 0.25        # –∑–µ—Ä–Ω–∏—Å—Ç–æ—Å—Ç—å –Ω–∞ —Ç–µ–∫—Å—Ç–µ (–ø–ª–µ–Ω–æ—á–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç)
TEXT_INNER_SHADOW_SIZE = 1         # –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ç–µ–Ω—å (–≥–ª—É–±–∏–Ω–∞ –±—É–∫–≤)
TEXT_SHARPEN_AMOUNT = 0.3          # —Ä–µ–∑–∫–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞ –ø–æ—Å–ª–µ —Ä–∞—Å—Ç—è–∂–µ–Ω–∏—è

# ============== –†–ê–°–¢–Ø–ñ–ï–ù–ò–ï –¢–ï–ö–°–¢–ê ==============
TEXT_STRETCH_HEIGHT = 2.1          # –≤—ã—Ç—è–≥–∏–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ –≤—ã—Å–æ—Ç–µ (—Ö2.1)
TEXT_STRETCH_WIDTH = 1.05          # –≤—ã—Ç—è–≥–∏–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ —à–∏—Ä–∏–Ω–µ (—Ö1.05)

# ============== –¢–ï–ù–ò / –û–ë–í–û–î–ö–ò ==============
TEXT_SHADOW_OFFSET = 3             # —Å–º–µ—â–µ–Ω–∏–µ —Ç–µ–Ω–∏ (–≤ –ø–∏–∫—Å–µ–ª—è—Ö)
TEXT_OUTLINE_THICKNESS = 2         # —Ç–æ–ª—â–∏–Ω–∞ –æ–±–≤–æ–¥–∫–∏ –±—É–∫–≤

# ============== –ë–õ–û–ö –¢–ï–ö–°–¢–ê ==============
TEXT_WIDTH_PERCENT = 0.90          # 90% —à–∏—Ä–∏–Ω—ã —ç–∫—Ä–∞–Ω–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞

# ============== OPENCV FALLBACK ==============
OPENCV_BLUR_SIGMA = 5              # —Ä–∞–∑–º—ã—Ç–∏–µ –ø—Ä–∏ fallback (–µ—Å–ª–∏ Replicate –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)
OPENCV_INPAINT_RADIUS = 3          # —Ä–∞–¥–∏—É—Å inpaint –ø—Ä–∏ fallback

# ============== –ü–£–¢–¨ –ö –®–†–ò–§–¢–£ ==============
FONT_PATH = os.getenv("FONT_PATH", "/app/fonts/WaffleSoft.otf").strip()

"""
==============================================
–ö–û–ù–ï–¶ –ù–ê–°–¢–†–û–ï–ö
==============================================
"""

openai.api_key = OPENAI_API_KEY


# ---------------------------------------------------------------------
# OCR (Google Vision)
# ---------------------------------------------------------------------
def google_vision_ocr(image_bgr: np.ndarray, crop_bottom_percent: int = OCR_BOTTOM_PERCENT) -> dict:
    if not GOOGLE_VISION_API_KEY:
        logger.warning("‚ö†Ô∏è GOOGLE_VISION_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return {"text": "", "lines": []}

    try:
        h, w = image_bgr.shape[:2]
        crop_start = int(h * (1 - crop_bottom_percent / 100))
        cropped = image_bgr[crop_start:, :]

        logger.info(f"üîç OCR –Ω–∞ {crop_bottom_percent}% —Å–Ω–∏–∑—É (—Å—Ç—Ä–æ–∫–∏ {crop_start}-{h})")

        rgb = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)
        pil_img = Image.fromarray(rgb)
        buf = BytesIO()
        pil_img.save(buf, format="PNG")
        image_base64 = base64.b64encode(buf.getvalue()).decode("utf-8")

        url = f"https://vision.googleapis.com/v1/images:annotate?key={GOOGLE_VISION_API_KEY}"
        payload = {
            "requests": [{
                "image": {"content": image_base64},
                "features": [{"type": "TEXT_DETECTION"}]
            }]
        }

        resp = requests.post(url, json=payload, timeout=30)
        data = resp.json()

        if not data.get("responses"):
            logger.warning("‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ OCR")
            return {"text": "", "lines": []}

        r0 = data["responses"][0]
        ann = r0.get("textAnnotations")
        if not ann:
            logger.warning("‚ö†Ô∏è –¢–µ–∫—Å—Ç –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω")
            return {"text": "", "lines": []}

        full_text = ann[0].get("description", "")
        lines = [ln.strip() for ln in full_text.split("\n") if ln.strip()]

        if lines and lines[0].strip().lower() in {"wealth", "@neurostep.media"}:
            lines = lines[1:]
            full_text = "\n".join(lines)

        logger.info(f"üìù OCR —Å—Ç—Ä–æ–∫–∏: {len(lines)}")
        return {"text": full_text.strip(), "lines": lines}

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ Google Vision OCR: {e}")
        return {"text": "", "lines": []}


def _preclean_ocr_for_cover(text: str) -> str:
    if not text:
        return text
    t = str(text)
    
    t = re.sub(r"@\S+", "", t)
    t = re.sub(r"(https?://\S+|www\.\S+)", "", t)
    t = re.sub(r"\b\d{1,2}:\d{2}\b", "", t)
    t = re.sub(r"[""¬´¬ª\"']", "", t)
    t = re.sub(r"[|‚Ä¢¬∑]+", " ", t)
    t = re.sub(r"\s*[-‚Äì‚Äî]{2,}\s*", " ", t)
    
    t = re.sub(r"(?i)\$\s*(\d+(?:\.\d+)?)\s*billion", r"$\1 –º–ª—Ä–¥.", t)
    t = re.sub(r"(?i)\$\s*(\d+(?:\.\d+)?)\s*million", r"$\1 –º–ª–Ω.", t)
    t = re.sub(r"(?i)\bmulti[-\s]?billion", "–º—É–ª—å—Ç–∏-–º–ª—Ä–¥.", t)
    t = re.sub(r"(?i)\bmulti[-\s]?million", "–º—É–ª—å—Ç–∏-–º–ª–Ω.", t)
    t = re.sub(r"(?i)\bbillion", "–º–ª—Ä–¥.", t)
    t = re.sub(r"(?i)\bmillion", "–º–ª–Ω.", t)
    
    t = re.sub(r"\b([A-Z]{2,})S\b", r"\1", t)
    
    t = re.sub(r"\s+", " ", t).strip()
    return t


def openai_translate(text: str) -> str:
    if not OPENAI_API_KEY or not text:
        logger.warning("‚ö†Ô∏è OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞")
        return text

    try:
        logger.info(f"üåê –ü–µ—Ä–µ–≤–æ–¥: {text}")
        clean_text = _preclean_ocr_for_cover(text)
        logger.info(f"üßπ –ü–æ—Å–ª–µ —á–∏—Å—Ç–∫–∏: {clean_text}")

        system_prompt = """–¢—ã ‚Äî –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ –∏ —Ä–µ–¥–∞–∫—Ç–æ—Ä –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–∏—Ç—Ä–æ–≤ –¥–ª—è –≤–∏–¥–µ–æ/–∫–∞—Ä—É—Å–µ–ª–∏. 
–ó–∞–¥–∞—á–∞: –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ —Å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π –∏ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è —ç–∫—Ä–∞–Ω–∞. 

–ü—Ä–∞–≤–∏–ª–∞:
1) –°–æ—Ö—Ä–∞–Ω—è–π –Ω–∞–∑–≤–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤/–±—Ä–µ–Ω–¥–æ–≤/–º–µ—Å—Ç (Antilia, Sea Wind, Mandarin Oriental, Tribeca –∏ —Ç.–ø.) –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ –ª–∞—Ç–∏–Ω–∏—Ü–µ–π, –Ω–æ –≥–æ—Ä–æ–¥–∞/—Ä–µ–≥–∏–æ–Ω—ã –ø–µ—Ä–µ–≤–æ–¥–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–π: Mumbai ‚Üí –ú—É–º–±–∞–∏, New York ‚Üí –ù—å—é-–ô–æ—Ä–∫, Buckinghamshire ‚Üí –ë–∞–∫–∏–Ω–≥–µ–º—à–∏—Ä.
2) –§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞: –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ –æ—Ç–¥–µ–ª—å–Ω–æ, –±–µ–∑ —Å–ø–∏—Å–∫–æ–≤ –∏ –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤. 
3) –î–µ–Ω–µ–∂–Ω—ã–µ —Å—É–º–º—ã –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–π –≤ —Ä—É—Å—Å–∫–æ–µ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ: 
   - million ‚Üí ¬´–º–ª–Ω $¬ª, billion ‚Üí ¬´–º–ª—Ä–¥ $¬ª
   - –¥–µ—Å—è—Ç–∏—á–Ω–∞—è –∑–∞–ø—è—Ç–∞—è: 4.6 ‚Üí 4,6
   - –∑–Ω–∞–∫ –≤–∞–ª—é—Ç—ã —Å—Ç–∞–≤—å –ø–æ—Å–ª–µ —á–∏—Å–ª–∞: ¬´79 –º–ª–Ω $¬ª, ¬´4,6 –º–ª—Ä–¥ $¬ª.
4) –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ ‚Äî —Å–ª–æ–≥–∞–Ω/—Ñ—Ä–∞–∑–∞, –ø–µ—Ä–µ–≤–µ–¥–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –±–µ–∑ –∫–∞–ª—å–∫–∏, –≤ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ-–¥–µ–ª–æ–≤–æ–º —Ç–æ–Ω–µ.
5) –ù–∏–∫–∞–∫–∏—Ö –¥–æ–±–∞–≤–ª–µ–Ω–∏–π —Ñ–∞–∫—Ç–æ–≤. –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π –¥–µ—Ç–∞–ª–∏. 
6) –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ/–æ–±—Ä—ã–≤ ‚Äî —Å–æ—Ö—Ä–∞–Ω–∏ –µ–≥–æ.

–í—Ö–æ–¥: –Ω–∞–±–æ—Ä —Å—Ç—Ä–æ–∫ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º (–∫–∞–∂–¥–∞—è —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏).
–í—ã—Ö–æ–¥: —Ç–æ—Ç –∂–µ –Ω–∞–±–æ—Ä —Å—Ç—Ä–æ–∫ –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –≤ —Ç–æ–º –∂–µ –ø–æ—Ä—è–¥–∫–µ.

‚úÖ –•–û–†–û–®–û:

"Aircraft" ‚Üí "–ò—Å—Ç—Ä–µ–±–∏—Ç–µ–ª—å"
"Northrop B-2 Spirit" ‚Üí "–°—Ç–µ–ª—Å-–±–æ–º–±–∞—Ä–¥–∏—Ä–æ–≤—â–∏–∫ B-2 Northrop Spirit"
"""

        resp = openai.ChatCompletion.create(
            model="gpt-4.1",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"–°–¥–µ–ª–∞–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –æ–±–ª–æ–∂–∫–∏: {clean_text}"},
            ],
            temperature=0.2,
            max_tokens=120,
        )

        translated = resp.choices[0].message.content.strip()

        translated = translated.strip().strip('"').strip("'").strip()
        translated = translated.rstrip(".")
        lines = [ln.strip() for ln in translated.splitlines() if ln.strip()]
        if len(lines) > 3:
            lines = lines[:3]
        translated = "\n".join(lines)

        logger.info(f"‚úÖ –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {translated}")
        return translated

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ OpenAI –ø–µ—Ä–µ–≤–æ–¥–∞: {e}")
        return text


def opencv_fallback(image_bgr: np.ndarray, mask_u8: np.ndarray) -> np.ndarray:
    if mask_u8.dtype != np.uint8:
        mask_u8 = mask_u8.astype(np.uint8)

    result = image_bgr.copy()

    blurred = cv2.GaussianBlur(image_bgr, (0, 0), sigmaX=OPENCV_BLUR_SIGMA, sigmaY=OPENCV_BLUR_SIGMA)
    result[mask_u8 == 255] = blurred[mask_u8 == 255]

    try:
        result = cv2.inpaint(result, mask_u8, inpaintRadius=OPENCV_INPAINT_RADIUS, flags=cv2.INPAINT_TELEA)
    except Exception:
        pass

    logger.info("‚úÖ OpenCV fallback (blur + light inpaint)")
    return result


def flux_inpaint(image_bgr: np.ndarray, mask_u8: np.ndarray) -> np.ndarray:
    if mask_u8.dtype != np.uint8:
        mask_u8 = mask_u8.astype(np.uint8)

    if not REPLICATE_API_TOKEN:
        logger.warning("‚ö†Ô∏è REPLICATE_API_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Üí fallback OpenCV")
        return opencv_fallback(image_bgr, mask_u8)

    try:
        import replicate
        client = replicate.Client(api_token=REPLICATE_API_TOKEN)

        logger.info(f"üöÄ Replicate inpaint: LaMa")

        rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
        pil_img = Image.fromarray(rgb)
        img_buf = BytesIO()
        pil_img.save(img_buf, format="PNG", compress_level=0)
        img_buf.seek(0)

        pil_mask = Image.fromarray(mask_u8, mode="L")
        mask_buf = BytesIO()
        pil_mask.save(mask_buf, format="PNG", compress_level=0)
        mask_buf.seek(0)

        output = client.run(
            "allenhooo/lama:cdac78a1bec5b23c07fd29692fb70baa513ea403a39e643c48ec5edadb15fe72",
            input={
                "image": img_buf,
                "mask": mask_buf
            }
        )

        if isinstance(output, str):
            r = requests.get(output, timeout=REPLICATE_HTTP_TIMEOUT)
            r.raise_for_status()
            result_bytes = r.content
        elif isinstance(output, list) and output:
            r = requests.get(output[0], timeout=REPLICATE_HTTP_TIMEOUT)
            r.raise_for_status()
            result_bytes = r.content
        elif hasattr(output, "read"):
            result_bytes = output.read()
        else:
            logger.error(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç output")
            return opencv_fallback(image_bgr, mask_u8)

        out_pil = Image.open(BytesIO(result_bytes)).convert("RGB")
        out_rgb = np.array(out_pil)
        out_bgr = cv2.cvtColor(out_rgb, cv2.COLOR_RGB2BGR)

        if out_bgr.shape[:2] != image_bgr.shape[:2]:
            logger.warning("‚ö†Ô∏è Replicate –∏–∑–º–µ–Ω–∏–ª —Ä–∞–∑–º–µ—Ä ‚Üí —Ä–µ—Å–∞–π–∑ –æ–±—Ä–∞—Ç–Ω–æ")
            out_bgr = cv2.resize(out_bgr, (image_bgr.shape[1], image_bgr.shape[0]), interpolation=cv2.INTER_LANCZOS4)

        if FORCE_PRESERVE_OUTSIDE_MASK:
            out_bgr = _composite_by_mask(image_bgr, out_bgr, mask_u8)

        logger.info("‚úÖ LaMa inpaint OK")
        return out_bgr

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ Replicate inpaint: {e}")
        return opencv_fallback(image_bgr, mask_u8)

def _composite_by_mask(original_bgr: np.ndarray, edited_bgr: np.ndarray, mask_u8: np.ndarray) -> np.ndarray:
    m = (mask_u8.astype(np.float32) / 255.0)[:, :, None]
    out = (original_bgr.astype(np.float32) * (1.0 - m) + edited_bgr.astype(np.float32) * m)
    return np.clip(out, 0, 255).astype(np.uint8)

def flux_kontext_inpaint(image: np.ndarray, mask: np.ndarray) -> np.ndarray:
    return flux_inpaint(image, mask)


def create_gradient_layer(width: int, height: int,
                          gradient_height_percent: int) -> Image.Image:
    
    grad_h = int(height * gradient_height_percent / 100)
    start_row = height - grad_h
    
    alpha = np.zeros(height, dtype=np.float32)
    
    for i in range(height):
        if i < start_row:
            alpha[i] = 0.0
        else:
            t = (height - 1 - i) / float(grad_h)
            
            if t <= GRADIENT_SOLID_FRACTION:
                alpha[i] = 1.0
            else:
                t_norm = (t - GRADIENT_SOLID_FRACTION) / (1.0 - GRADIENT_SOLID_FRACTION)
                alpha[i] = 1.0 - (t_norm ** GRADIENT_TRANSITION_CURVE)
    
    alpha_u8 = (alpha * 255).astype(np.uint8)
    alpha_2d = np.tile(alpha_u8[:, None], (1, width))
    
    if GRADIENT_NOISE_INTENSITY > 0:
        noise = np.random.normal(0, GRADIENT_NOISE_INTENSITY, (height, width)).astype(np.float32)
        alpha_2d_float = alpha_2d.astype(np.float32) + noise
        alpha_2d = np.clip(alpha_2d_float, 0, 255).astype(np.uint8)
    
    ksize_y = int(GRADIENT_BLUR_SIGMA * 6) | 1
    alpha_blurred = cv2.GaussianBlur(alpha_2d, (1, ksize_y), sigmaX=0, sigmaY=GRADIENT_BLUR_SIGMA)
    
    rgba = np.zeros((height, width, 4), dtype=np.uint8)
    rgba[:, :, 3] = alpha_blurred
    
    logger.info(f"‚ú® –ì—Ä–∞–¥–∏–µ–Ω—Ç: {gradient_height_percent}%, solid={GRADIENT_SOLID_FRACTION*100}%, blur={GRADIENT_BLUR_SIGMA}, noise={GRADIENT_NOISE_INTENSITY}")
    return Image.fromarray(rgba, mode="RGBA")


def enhance_image(image_bgr: np.ndarray) -> np.ndarray:
    
    enhanced = cv2.convertScaleAbs(image_bgr, alpha=ENHANCE_CONTRAST, beta=(ENHANCE_BRIGHTNESS - 1.0) * 30)
    
    hsv = cv2.cvtColor(enhanced, cv2.COLOR_BGR2HSV).astype(np.float32)
    hsv[:, :, 1] = np.clip(hsv[:, :, 1] * ENHANCE_SATURATION, 0, 255)
    enhanced = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)
    
    if ENHANCE_SHARPNESS > 1.0:
        blurred = cv2.GaussianBlur(enhanced, (0, 0), 3)
        enhanced = cv2.addWeighted(enhanced, ENHANCE_SHARPNESS, blurred, -(ENHANCE_SHARPNESS - 1.0), 0)
    
    logger.info(f"üì∏ –£–ª—É—á—à–µ–Ω–∏–µ: —è—Ä–∫–æ—Å—Ç—å={ENHANCE_BRIGHTNESS:.2f}, –∫–æ–Ω—Ç—Ä–∞—Å—Ç={ENHANCE_CONTRAST:.2f}, –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å={ENHANCE_SATURATION:.2f}, —Ä–µ–∑–∫–æ—Å—Ç—å={ENHANCE_SHARPNESS:.2f}")
    return enhanced


def calculate_adaptive_font_size(text: str, font_path: str, max_width: int,
                                 initial_size: int, min_size: int = FONT_SIZE_MIN,
                                 stretch_width: float = TEXT_STRETCH_WIDTH) -> tuple:
    text = (text or "").strip()
    if not text:
        font = ImageFont.truetype(font_path, int(min_size))
        return int(min_size), font, [""]

    words = text.split()
    if not words:
        font = ImageFont.truetype(font_path, int(min_size))
        return int(min_size), font, [text]

    size = int(initial_size)
    while size >= int(min_size):
        try:
            font = ImageFont.truetype(font_path, int(size))
            lines = _wrap_greedy(words, font, max_width, stretch_width)
            if lines:
                return int(size), font, lines
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —à—Ä–∏—Ñ—Ç–∞ {size}: {e}")
        size -= 2

    font = ImageFont.truetype(font_path, int(min_size))
    return int(min_size), font, [text]


def _wrap_greedy(words: list, font: ImageFont.FreeTypeFont, max_width: int, stretch: float) -> list:
    if not words:
        return []
    
    space_w = max(1, _text_width_px(font, " ", spacing=LETTER_SPACING_PX))
    lines = []
    current = []
    current_w = 0
    
    for w in words:
        w_width = _text_width_px(font, w, spacing=LETTER_SPACING_PX)
        test_w = current_w + (space_w if current else 0) + w_width
        
        if current and int(test_w * stretch) > max_width:
            lines.append(" ".join(current))
            current = [w]
            current_w = w_width
        else:
            current.append(w)
            current_w = test_w
    
    if current:
        lines.append(" ".join(current))
    
    return lines if lines else []


def _text_width_px(font: ImageFont.FreeTypeFont, text: str, spacing: int = 0) -> int:
    bb = font.getbbox(text)
    base_width = int(bb[2] - bb[0])
    
    if spacing > 0 and len(text) > 1:
        return base_width + (len(text) - 1) * spacing
    
    return base_width


def _draw_text_with_letter_spacing(draw: ImageDraw.ImageDraw, pos: tuple, text: str, 
                                   font: ImageFont.FreeTypeFont, fill: tuple, spacing: int = 0) -> int:
    if spacing <= 0:
        draw.text(pos, text, font=font, fill=fill)
        bb = font.getbbox(text)
        return int(bb[2] - bb[0])
    
    x, y = pos
    total_width = 0
    
    for char in text:
        draw.text((x, y), char, font=font, fill=fill)
        bb = font.getbbox(char)
        char_width = int(bb[2] - bb[0])
        x += char_width + spacing
        total_width += char_width + spacing
    
    return total_width - spacing if total_width > 0 else 0


def draw_text_with_stretch(base_image: Image.Image,
                           x: int, y: int,
                           text: str,
                           font: ImageFont.FreeTypeFont,
                           fill_color: tuple,
                           outline_color: tuple,
                           stretch_width: float = TEXT_STRETCH_WIDTH,
                           stretch_height: float = TEXT_STRETCH_HEIGHT,
                           shadow_offset: int = TEXT_SHADOW_OFFSET,
                           apply_enhancements: bool = True) -> int:
    bbox = font.getbbox(text)
    tw = _text_width_px(font, text, spacing=LETTER_SPACING_PX)
    th = bbox[3] - bbox[1]

    pad = max(6, shadow_offset + TEXT_OUTLINE_THICKNESS * 2)
    temp_w = int(tw * (stretch_width + 1.0)) + pad * 2
    temp_h = int(th * (stretch_height + 1.0)) + pad * 2

    temp = Image.new("RGBA", (temp_w, temp_h), (0, 0, 0, 0))
    d = ImageDraw.Draw(temp)

    tx, ty = pad, pad

    _draw_text_with_letter_spacing(d, (tx + shadow_offset, ty + shadow_offset), text, font, (0, 0, 0, 128), spacing=LETTER_SPACING_PX)

    for t in range(int(TEXT_OUTLINE_THICKNESS)):
        r = t + 1
        for dx, dy in [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]:
            _draw_text_with_letter_spacing(d, (tx + dx * r, ty + dy * r), text, font, outline_color, spacing=LETTER_SPACING_PX)

    _draw_text_with_letter_spacing(d, (tx, ty), text, font, fill_color, spacing=LETTER_SPACING_PX)
    
    if apply_enhancements:
        if TEXT_INNER_SHADOW_SIZE > 0:
            temp_arr = np.array(temp)
            alpha = temp_arr[:, :, 3]
            
            kernel = np.ones((TEXT_INNER_SHADOW_SIZE * 2 + 1, TEXT_INNER_SHADOW_SIZE * 2 + 1), np.uint8)
            eroded = cv2.erode(alpha, kernel, iterations=1)
            inner_shadow_mask = (alpha > 0) & (eroded == 0)
            
            temp_arr[inner_shadow_mask, :3] = temp_arr[inner_shadow_mask, :3] * 0.7
            temp = Image.fromarray(temp_arr)
        
        if TEXT_GRAIN_INTENSITY > 0:
            temp_arr = np.array(temp).astype(np.float32)
            alpha = temp_arr[:, :, 3]
            
            noise = np.random.normal(0, TEXT_GRAIN_INTENSITY * 25, (temp_h, temp_w, 3))
            text_mask = alpha > 0
            
            temp_arr[:, :, :3][text_mask] += noise[text_mask]
            temp_arr = np.clip(temp_arr, 0, 255).astype(np.uint8)
            temp = Image.fromarray(temp_arr)

    bb = temp.getbbox()
    if not bb:
        return th

    crop = temp.crop(bb)
    sw = max(1, int(crop.width * stretch_width))
    sh = max(1, int(crop.height * stretch_height))
    crop = crop.resize((sw, sh), Image.Resampling.LANCZOS)
    
    if apply_enhancements and TEXT_SHARPEN_AMOUNT > 0:
        crop_arr = np.array(crop).astype(np.float32)
        rgb = crop_arr[:, :, :3]
        alpha = crop_arr[:, :, 3:4]
        
        blurred = cv2.GaussianBlur(rgb, (0, 0), 1.0)
        sharpened = rgb + TEXT_SHARPEN_AMOUNT * (rgb - blurred)
        sharpened = np.clip(sharpened, 0, 255)
        
        crop_arr[:, :, :3] = sharpened
        crop = Image.fromarray(crop_arr.astype(np.uint8))

    base_image.paste(crop, (x, y), crop)
    return sh


def _estimate_fixed_line_height(font: ImageFont.FreeTypeFont) -> int:
    try:
        ascent, descent = font.getmetrics()
        base = int((ascent + descent) * TEXT_STRETCH_HEIGHT)
    except Exception:
        base = int(font.size * TEXT_STRETCH_HEIGHT)
    pad = max(6, TEXT_SHADOW_OFFSET + int(TEXT_OUTLINE_THICKNESS) * 2)
    return base + pad


# ============== –†–ï–ñ–ò–ú 1 ==============
def render_mode1_logo(image: Image.Image, title_translated: str) -> Image.Image:
    image = image.convert("RGBA")
    draw = ImageDraw.Draw(image, "RGBA")
    width, height = image.size
    max_text_width = int(width * TEXT_WIDTH_PERCENT)

    title = (title_translated or "").upper()
    _, title_font, title_lines = calculate_adaptive_font_size(
        title, FONT_PATH, max_text_width, FONT_SIZE_MODE1, stretch_width=TEXT_STRETCH_WIDTH
    )

    # –ü–†–û–•–û–î 1: –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≤—ã—Å–æ—Ç—É
    temp_img = Image.new("RGBA", (width, height), (0, 0, 0, 0))
    max_h = 0
    for ln in title_lines:
        actual_h = draw_text_with_stretch(temp_img, 0, 0, ln, title_font, COLOR_TURQUOISE, COLOR_OUTLINE)
        max_h = max(max_h, actual_h)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º max_h –∫–∞–∫ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤—ã—Å–æ—Ç—É —Å—Ç—Ä–æ–∫–∏
    line_h = max_h
    total_title_h = line_h * len(title_lines) + max(0, (len(title_lines) - 1) * LINE_SPACING)

    logo_font = ImageFont.truetype(FONT_PATH, FONT_SIZE_LOGO)
    logo_text = "@neurostep.media"
    bb = logo_font.getbbox(logo_text)
    logo_w = bb[2] - bb[0]
    logo_h = bb[3] - bb[1]

    total_h = logo_h + SPACING_LOGO_TO_TITLE + total_title_h
    start_y = height - SPACING_BOTTOM_MODE1 - total_h

    logo_x = (width - logo_w) // 2
    logo_y = start_y

    line_y = logo_y + logo_h // 2
    line_left_start = logo_x - LOGO_LINE_LENGTH - 10
    line_right_start = logo_x + logo_w + 10

    draw.line([(line_left_start, line_y), (line_left_start + LOGO_LINE_LENGTH, line_y)], fill=COLOR_TURQUOISE, width=LOGO_LINE_THICKNESS_PX)
    draw.line([(line_right_start, line_y), (line_right_start + LOGO_LINE_LENGTH, line_y)], fill=COLOR_TURQUOISE, width=LOGO_LINE_THICKNESS_PX)
    draw.text((logo_x, logo_y), logo_text, font=logo_font, fill=COLOR_WHITE)

    # –ü–†–û–•–û–î 2: –†–µ–Ω–¥–µ—Ä —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º line_h
    cur_y = start_y + logo_h + SPACING_LOGO_TO_TITLE
    block_left = (width - max_text_width) // 2
    
    for i, ln in enumerate(title_lines):
        line_w = int(_text_width_px(title_font, ln, spacing=LETTER_SPACING_PX) * TEXT_STRETCH_WIDTH)
        line_x = block_left + (max_text_width - line_w) // 2
        draw_text_with_stretch(image, line_x, cur_y, ln, title_font, COLOR_TURQUOISE, COLOR_OUTLINE)
        cur_y += line_h  # –§–ò–ö–°–ò–†–û–í–ê–ù–ù–ê–Ø –í–´–°–û–¢–ê
        if i < len(title_lines) - 1:
            cur_y += LINE_SPACING

    return image


# ============== –†–ï–ñ–ò–ú 2 ==============
def render_mode2_text(image: Image.Image, title_translated: str) -> Image.Image:
    image = image.convert("RGBA")
    width, height = image.size
    max_text_width = int(width * TEXT_WIDTH_PERCENT)

    title = (title_translated or "").upper()
    _, title_font, title_lines = calculate_adaptive_font_size(
        title, FONT_PATH, max_text_width, FONT_SIZE_MODE2, stretch_width=TEXT_STRETCH_WIDTH
    )

    # –ü–†–û–•–û–î 1: –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≤—ã—Å–æ—Ç—É
    temp_img = Image.new("RGBA", (width, height), (0, 0, 0, 0))
    max_h = 0
    for ln in title_lines:
        actual_h = draw_text_with_stretch(temp_img, 0, 0, ln, title_font, COLOR_TURQUOISE, COLOR_OUTLINE)
        max_h = max(max_h, actual_h)
    
    line_h = max_h
    total_h = line_h * len(title_lines) + max(0, (len(title_lines) - 1) * LINE_SPACING)

    start_y = height - SPACING_BOTTOM_MODE2 - total_h
    cur_y = start_y
    block_left = (width - max_text_width) // 2

    # –ü–†–û–•–û–î 2: –†–µ–Ω–¥–µ—Ä —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º line_h
    for i, ln in enumerate(title_lines):
        line_w = int(_text_width_px(title_font, ln, spacing=LETTER_SPACING_PX) * TEXT_STRETCH_WIDTH)
        line_x = block_left + (max_text_width - line_w) // 2
        draw_text_with_stretch(image, line_x, cur_y, ln, title_font, COLOR_TURQUOISE, COLOR_OUTLINE)
        cur_y += line_h  # –§–ò–ö–°–ò–†–û–í–ê–ù–ù–ê–Ø –í–´–°–û–¢–ê
        if i < len(title_lines) - 1:
            cur_y += LINE_SPACING

    return image


# ============== –†–ï–ñ–ò–ú 3 ==============
def render_mode3_content(image: Image.Image, title_translated: str, subtitle_translated: str) -> Image.Image:
    image = image.convert("RGBA")
    width, height = image.size
    max_text_width = int(width * TEXT_WIDTH_PERCENT)

    title = (title_translated or "").upper()
    subtitle = (subtitle_translated or "").upper()

    title_size, title_font, title_lines = calculate_adaptive_font_size(
        title, FONT_PATH, max_text_width, FONT_SIZE_MODE3_TITLE, stretch_width=TEXT_STRETCH_WIDTH
    )

    subtitle_initial = int(title_size * 0.80)
    _, subtitle_font, subtitle_lines = calculate_adaptive_font_size(
        subtitle, FONT_PATH, max_text_width, subtitle_initial, stretch_width=TEXT_STRETCH_WIDTH
    )

    # –ü–†–û–•–û–î 1: –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –≤—ã—Å–æ—Ç—ã
    temp_img = Image.new("RGBA", (width, height), (0, 0, 0, 0))
    
    max_title_h = 0
    for ln in title_lines:
        actual_h = draw_text_with_stretch(temp_img, 0, 0, ln, title_font, COLOR_TURQUOISE, COLOR_OUTLINE)
        max_title_h = max(max_title_h, actual_h)
    
    max_sub_h = 0
    for ln in subtitle_lines:
        actual_h = draw_text_with_stretch(temp_img, 0, 0, ln, subtitle_font, COLOR_WHITE, COLOR_OUTLINE)
        max_sub_h = max(max_sub_h, actual_h)

    title_line_h = max_title_h
    sub_line_h = max_sub_h

    total_title_h = title_line_h * len(title_lines) + max(0, (len(title_lines) - 1) * LINE_SPACING)
    total_sub_h = sub_line_h * len(subtitle_lines) + max(0, (len(subtitle_lines) - 1) * LINE_SPACING)

    total_h = total_title_h + SPACING_TITLE_TO_SUBTITLE + total_sub_h
    start_y = height - SPACING_BOTTOM_MODE3 - total_h

    cur_y = start_y
    block_left = (width - max_text_width) // 2

    # –ü–†–û–•–û–î 2: –†–µ–Ω–¥–µ—Ä –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    for i, ln in enumerate(title_lines):
        line_w = int(_text_width_px(title_font, ln, spacing=LETTER_SPACING_PX) * TEXT_STRETCH_WIDTH)
        line_x = block_left + (max_text_width - line_w) // 2
        draw_text_with_stretch(image, line_x, cur_y, ln, title_font, COLOR_TURQUOISE, COLOR_OUTLINE)
        cur_y += title_line_h
        if i < len(title_lines) - 1:
            cur_y += LINE_SPACING

    cur_y += SPACING_TITLE_TO_SUBTITLE

    # –ü–†–û–•–û–î 2: –†–µ–Ω–¥–µ—Ä –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    for i, ln in enumerate(subtitle_lines):
        line_w = int(_text_width_px(subtitle_font, ln, spacing=LETTER_SPACING_PX) * TEXT_STRETCH_WIDTH)
        line_x = block_left + (max_text_width - line_w) // 2
        draw_text_with_stretch(image, line_x, cur_y, ln, subtitle_font, COLOR_WHITE, COLOR_OUTLINE)
        cur_y += sub_line_h
        if i < len(subtitle_lines) - 1:
            cur_y += LINE_SPACING

    return image


def process_full_workflow(image_bgr: np.ndarray, mode: int) -> tuple:
    logger.info("=" * 60)
    logger.info(f"üöÄ –ü–û–õ–ù–´–ô WORKFLOW - –†–ï–ñ–ò–ú {mode}")
    logger.info("=" * 60)

    h, w = image_bgr.shape[:2]

    logger.info("üìã –®–ê–ì 1: OCR (Google Vision)")
    ocr = google_vision_ocr(image_bgr, crop_bottom_percent=OCR_BOTTOM_PERCENT)
    if not ocr["text"]:
        logger.warning("‚ö†Ô∏è –¢–µ–∫—Å—Ç –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω")
        return image_bgr, ocr

    logger.info("üìã –®–ê–ì 2: –ú–∞—Å–∫–∞ (–Ω–∏–∂–Ω–∏–µ %)")
    mask = np.zeros((h, w), dtype=np.uint8)
    mask_start = int(h * (1 - MASK_BOTTOM_PERCENT / 100))
    mask[mask_start:, :] = 255
    logger.info(f"üìê –ú–∞—Å–∫–∞: —Å—Ç—Ä–æ–∫–∏ {mask_start}-{h} (–Ω–∏–∂–Ω–∏–µ {MASK_BOTTOM_PERCENT}%)")

    logger.info("üìã –®–ê–ì 3: Inpaint (Replicate FLUX Fill)")
    clean_bgr = flux_inpaint(image_bgr, mask)

    logger.info("üìã –®–ê–ì 4: –ü–µ—Ä–µ–≤–æ–¥ (OpenAI)")
    title_translated, subtitle_translated = "", ""

    if mode == 3:
        lines = ocr["lines"]
        if len(lines) >= 2:
            title = " ".join(lines[:-1])
            subtitle = lines[-1]
        else:
            title, subtitle = ocr["text"], ""

        title_translated = openai_translate(title)
        subtitle_translated = openai_translate(subtitle) if subtitle else ""
    else:
        title_translated = openai_translate(ocr["text"])

    logger.info("üìã –®–ê–ì 5: –ì—Ä–∞–¥–∏–µ–Ω—Ç")
    clean_rgb = cv2.cvtColor(clean_bgr, cv2.COLOR_BGR2RGB)
    pil = Image.fromarray(clean_rgb).convert("RGBA")

    if mode == 3:
        grad = create_gradient_layer(pil.size[0], pil.size[1], gradient_height_percent=GRADIENT_HEIGHT_MODE3)
    else:
        grad = create_gradient_layer(pil.size[0], pil.size[1], gradient_height_percent=GRADIENT_HEIGHT_MODE12)
    pil = Image.alpha_composite(pil, grad)
    logger.info("‚úÖ –ì—Ä–∞–¥–∏–µ–Ω—Ç –Ω–∞–ª–æ–∂–µ–Ω")

    logger.info("üìã –®–ê–ì 6: –†–µ–Ω–¥–µ—Ä —Ç–µ–∫—Å—Ç–∞")
    if mode == 1:
        pil = render_mode1_logo(pil, title_translated)
    elif mode == 2:
        pil = render_mode2_text(pil, title_translated)
    elif mode == 3:
        pil = render_mode3_content(pil, title_translated, subtitle_translated)
    else:
        logger.warning(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º {mode} ‚Üí –ø—Ä–æ–ø—É—Å–∫–∞—é —Ä–µ–Ω–¥–µ—Ä")

    out_rgb = np.array(pil.convert("RGB"))
    out_bgr = cv2.cvtColor(out_rgb, cv2.COLOR_RGB2BGR)

    logger.info("=" * 60)
    logger.info("‚úÖ WORKFLOW –ó–ê–í–ï–†–®–Å–ù!")
    logger.info("=" * 60)
    return out_bgr, ocr


def replicate_inpaint(image: np.ndarray, mask: np.ndarray) -> np.ndarray:
    return flux_inpaint(image, mask)
