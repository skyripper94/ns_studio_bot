# lama_integration.py

# ============== –ò–ú–ü–û–†–¢–´ ==============
import os
import logging
import base64
from io import BytesIO

import numpy as np
import cv2
import requests
from PIL import Image, ImageDraw, ImageFont

import openai
import re

logger = logging.getLogger(__name__)

"""
==============================================
–ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø –ë–´–°–¢–†–û–ô –†–£–ß–ù–û–ô –ü–†–ê–í–ö–ò
==============================================
"""

# ============== API –ö–õ–Æ–ß–ò ==============
REPLICATE_API_TOKEN = os.getenv("REPLICATE_API_TOKEN", "").strip()
GOOGLE_VISION_API_KEY = os.getenv("GOOGLE_VISION_API_KEY", "").strip()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()

# ============== REPLICATE / FLUX (INPAINT) ==============
# –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ï –ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–´ (mask-aware, –±–µ–∑ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤):
# 1. allenhooo/lama - –¢–û–ü! –ë—ã—Å—Ç—Ä–æ (~3—Å–µ–∫), —Ç–æ—á–Ω–æ, –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ñ–æ–Ω –ë–ï–ó –¥–æ–¥—É–º—ã–≤–∞–Ω–∏—è
# 2. bria/eraser - SOTA —É–¥–∞–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤, –±–µ–∑ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
# 3. stability-ai/stable-diffusion-inpainting - –∫–ª–∞—Å—Å–∏–∫–∞, mask-aware
REPLICATE_MODEL = os.getenv("REPLICATE_MODEL", "black-forest-labs/flux-fill-pro").strip()
FLUX_STEPS = int(os.getenv("FLUX_STEPS", "50"))
FLUX_GUIDANCE = float(os.getenv("FLUX_GUIDANCE", "3.5"))
FLUX_OUTPUT_FORMAT = os.getenv("FLUX_OUTPUT_FORMAT", "png")
FLUX_PROMPT_UPSAMPLING = False
REPLICATE_HTTP_TIMEOUT = int(os.getenv("REPLICATE_HTTP_TIMEOUT", "120"))

FORCE_PRESERVE_OUTSIDE_MASK = True

# ============== –¶–í–ï–¢–ê ==============
COLOR_TURQUOISE = (0, 206, 209)
COLOR_WHITE = (255, 255, 255)
COLOR_OUTLINE = (60, 60, 60)

# ============== –†–ê–ó–ú–ï–†–´ –®–†–ò–§–¢–û–í ==============
FONT_SIZE_MODE1 = 52
FONT_SIZE_MODE2 = 50
FONT_SIZE_MODE3_TITLE = 50
FONT_SIZE_MODE3_SUBTITLE = 48
FONT_SIZE_LOGO = 24
FONT_SIZE_MIN = 44

# ============== –û–¢–°–¢–£–ü–´ –ò –†–ê–°–°–¢–û–Ø–ù–ò–Ø ==============
SPACING_BOTTOM = -41
SPACING_BOTTOM_MODE3 = 41
SPACING_LOGO_TO_TITLE = 8
SPACING_TITLE_TO_SUBTITLE = -38
LINE_SPACING = -37
LOGO_LINE_LENGTH = 310
LOGO_LINE_THICKNESS_PX = 3

# ============== –ú–ê–°–ö–ê / OCR ==============
MASK_BOTTOM_PERCENT = 32
OCR_BOTTOM_PERCENT = 32

# ============== –ì–†–ê–î–ò–ï–ù–¢ (Instagram-—Å—Ç–∏–ª—å) ==============
GRADIENT_HEIGHT_MODE12 = 45  # % –≤—ã—Å–æ—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —Ä–µ–∂–∏–º–æ–≤ 1-2
GRADIENT_HEIGHT_MODE3 = 35   # % –≤—ã—Å–æ—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —Ä–µ–∂–∏–º–∞ 3
GRADIENT_SOLID_FRACTION = 0.5  # 50% –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ = —Å–ø–ª–æ—à–Ω–æ–π —á–µ—Ä–Ω—ã–π
GRADIENT_TRANSITION_CURVE = 2.2  # –ø–ª–∞–≤–Ω–æ—Å—Ç—å –ø–µ—Ä–µ—Ö–æ–¥–∞ (–≤—ã—à–µ = –º—è–≥—á–µ)
GRADIENT_BLUR_SIGMA = 120  # —Ä–∞–∑–º—ã—Ç–∏–µ –¥–ª—è —Ä–∞—Å—Å–µ–∏–≤–∞–Ω–∏—è (–≤—ã—à–µ = —Å–∏–ª—å–Ω–µ–µ)

# ============== –†–ê–°–¢–Ø–ñ–ï–ù–ò–ï –¢–ï–ö–°–¢–ê ==============
TEXT_STRETCH_HEIGHT = 2.1
TEXT_STRETCH_WIDTH = 1.05

# ============== –¢–ï–ù–ò / –û–ë–í–û–î–ö–ò ==============
TEXT_SHADOW_OFFSET = 2
TEXT_OUTLINE_THICKNESS = 1

# ============== –ë–õ–û–ö –¢–ï–ö–°–¢–ê ==============
TEXT_WIDTH_PERCENT = 0.90

# ============== OPENCV FALLBACK ==============
OPENCV_BLUR_SIGMA = 5
OPENCV_INPAINT_RADIUS = 3

# ============== –ü–£–¢–¨ –ö –®–†–ò–§–¢–£ ==============
FONT_PATH = os.getenv("FONT_PATH", "/app/fonts/WaffleSoft.otf").strip()

"""
==============================================
–ö–û–ù–ï–¶ –ù–ê–°–¢–†–û–ï–ö
==============================================
"""

openai.api_key = OPENAI_API_KEY


# ---------------------------------------------------------------------
# OCR (Google Vision)
# ---------------------------------------------------------------------
def google_vision_ocr(image_bgr: np.ndarray, crop_bottom_percent: int = OCR_BOTTOM_PERCENT) -> dict:
    """OCR —á–µ—Ä–µ–∑ Google Vision API –ø–æ –Ω–∏–∂–Ω–µ–π —á–∞—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    if not GOOGLE_VISION_API_KEY:
        logger.warning("‚ö†Ô∏è GOOGLE_VISION_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return {"text": "", "lines": []}

    try:
        h, w = image_bgr.shape[:2]
        crop_start = int(h * (1 - crop_bottom_percent / 100))
        cropped = image_bgr[crop_start:, :]

        logger.info(f"üîç OCR –Ω–∞ {crop_bottom_percent}% —Å–Ω–∏–∑—É (—Å—Ç—Ä–æ–∫–∏ {crop_start}-{h})")

        rgb = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)
        pil_img = Image.fromarray(rgb)
        buf = BytesIO()
        pil_img.save(buf, format="PNG")
        image_base64 = base64.b64encode(buf.getvalue()).decode("utf-8")

        url = f"https://vision.googleapis.com/v1/images:annotate?key={GOOGLE_VISION_API_KEY}"
        payload = {
            "requests": [{
                "image": {"content": image_base64},
                "features": [{"type": "TEXT_DETECTION"}]
            }]
        }

        resp = requests.post(url, json=payload, timeout=30)
        data = resp.json()

        if not data.get("responses"):
            logger.warning("‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ OCR")
            return {"text": "", "lines": []}

        r0 = data["responses"][0]
        ann = r0.get("textAnnotations")
        if not ann:
            logger.warning("‚ö†Ô∏è –¢–µ–∫—Å—Ç –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω")
            return {"text": "", "lines": []}

        full_text = ann[0].get("description", "")
        lines = [ln.strip() for ln in full_text.split("\n") if ln.strip()]

        if lines and lines[0].strip().lower() in {"wealth", "@neurostep.media"}:
            lines = lines[1:]
            full_text = "\n".join(lines)

        logger.info(f"üìù OCR —Å—Ç—Ä–æ–∫–∏: {len(lines)}")
        return {"text": full_text.strip(), "lines": lines}

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ Google Vision OCR: {e}")
        return {"text": "", "lines": []}


# ---------------------------------------------------------------------
# –ß–∏—Å—Ç–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ (–ø–µ—Ä–µ–¥ OpenAI)
# ---------------------------------------------------------------------
def _preclean_ocr_for_cover(text: str) -> str:
    if not text:
        return text
    t = str(text)
    
    t = re.sub(r"@\S+", "", t)
    t = re.sub(r"(https?://\S+|www\.\S+)", "", t)
    t = re.sub(r"\b\d{1,2}:\d{2}\b", "", t)
    t = re.sub(r"[""¬´¬ª\"']", "", t)
    t = re.sub(r"[|‚Ä¢¬∑]+", " ", t)
    t = re.sub(r"\s*[-‚Äì‚Äî]{2,}\s*", " ", t)
    
    t = re.sub(r"(?i)\$\s*(\d+(?:\.\d+)?)\s*billion", r"$\1 –º–ª—Ä–¥.", t)
    t = re.sub(r"(?i)\$\s*(\d+(?:\.\d+)?)\s*million", r"$\1 –º–ª–Ω.", t)
    t = re.sub(r"(?i)\bmulti[-\s]?billion", "–º—É–ª—å—Ç–∏-–º–ª—Ä–¥.", t)
    t = re.sub(r"(?i)\bmulti[-\s]?million", "–º—É–ª—å—Ç–∏-–º–ª–Ω.", t)
    t = re.sub(r"(?i)\bbillion", "–º–ª—Ä–¥.", t)
    t = re.sub(r"(?i)\bmillion", "–º–ª–Ω.", t)
    
    t = re.sub(r"\b([A-Z]{2,})S\b", r"\1", t)
    
    t = re.sub(r"\s+", " ", t).strip()
    return t


# ---------------------------------------------------------------------
# –ü–µ—Ä–µ–≤–æ–¥ (OpenAI)
# ---------------------------------------------------------------------
def openai_translate(text: str) -> str:
    """–ü–µ—Ä–µ–≤–æ–¥ –∏ –∞–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ –°–ù–ì."""
    if not OPENAI_API_KEY or not text:
        logger.warning("‚ö†Ô∏è OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞")
        return text

    try:
        logger.info(f"üåê –ü–µ—Ä–µ–≤–æ–¥: {text}")
        clean_text = _preclean_ocr_for_cover(text)
        logger.info(f"üßπ –ü–æ—Å–ª–µ —á–∏—Å—Ç–∫–∏: {clean_text}")

        system_prompt = """–ü–†–û–°–¢–û –ü–ï–†–ï–í–ï–î–ò

‚ùå –ü–õ–û–•–û:
"Will leave you speechless" ‚Üí "–ó–∞—Å—Ç–∞–≤–∏—Ç –æ—Ç–∫—Ä—ã—Ç—å —Ä–æ—Ç"
"Empire that owns everything" ‚Üí "–ò–º–ø–µ—Ä–∏—è Ambani –≤–ª–∞–¥–µ–µ—Ç –≤—Å–µ–º"

‚úÖ –•–û–†–û–®–û:
"Will leave you speechless" ‚Üí "–ú–∞—Å—à—Ç–∞–±—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ç—Ä—É–¥–Ω–æ –æ—Å–æ–∑–Ω–∞—Ç—å"
"Empire that owns everything" ‚Üí "–ü–æ—Ä—Ç—Ñ–µ–ª—å –∞–∫—Ç–∏–≤–æ–≤ –Ω–∞ $50 –º–ª—Ä–¥."
"Aircraft" ‚Üí "–ò—Å—Ç—Ä–µ–±–∏—Ç–µ–ª—å"
"Northrop B-2 Spirit" ‚Üí "–°—Ç–µ–ª—Å-–±–æ–º–±–∞—Ä–¥–∏—Ä–æ–≤—â–∏–∫ B-2 Northrop Spirit"

–ü–†–ò–ú–ï–†–´ –ü–ï–†–ï–í–û–î–û–í:

1) "AMBANI'S MULTI-BILLION DOLLAR PROPERTY EMPIRE WILL LEAVE YOU SPEECHLESS"
‚Üí "–ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å Ambani –Ω–∞ –º–∏–ª–ª–∏–∞—Ä–¥—ã: –º–∞—Å—à—Ç–∞–±—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ç—Ä—É–¥–Ω–æ –æ—Å–æ–∑–Ω–∞—Ç—å"
‚Üí "–ú–∏–ª–ª–∏–∞—Ä–¥–Ω–∞—è –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å Ambani: —ç—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç –Ω–µ—Ä–µ–∞–ª—å–Ω–æ"

2) "THE MOST EXPENSIVE THINGS HUMANS HAVE EVER CREATED"
‚Üí "–°–∞–º—ã–µ –¥–æ—Ä–æ–≥–∏–µ —Ç–≤–æ—Ä–µ–Ω–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å—Ç–≤–∞"

3) "TESLA'S REVOLUTIONARY TECHNOLOGY WILL CHANGE EVERYTHING"
‚Üí "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è Tesla: —á—Ç–æ –∏–∑–º–µ–Ω–∏—Ç—Å—è –≤ –±–ª–∏–∂–∞–π—à–∏–µ –≥–æ–¥—ã"

4) "INSIDE BILLIONAIRE'S $500 MILLION MANSION"
‚Üí "–û—Å–æ–±–Ω—è–∫ –∑–∞ $500 –º–ª–Ω.: –∫–∞–∫ —ç—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç –∏–∑–Ω—É—Ç—Ä–∏"

5) "THIS WILL BLOW YOUR MIND"
‚Üí "–≠—Ç–æ –º–µ–Ω—è–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ"

6) "YOU WON'T BELIEVE WHAT THEY BUILT"
‚Üí "–ß—Ç–æ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å: –Ω–µ–≤–µ—Ä–æ—è—Ç–Ω—ã–µ –º–∞—Å—à—Ç–∞–±—ã"

–ó–ê–ü–†–ï–©–ï–ù–û:
- –û–±—Ä–∞—â–µ–Ω–∏—è: –í–ê–°, –¢–ï–ë–Ø, –í–´
- –û–±–µ—â–∞–Ω–∏—è: –ó–ê–°–¢–ê–í–ò–¢, –û–¢–ö–†–û–ï–¢ –†–û–¢, –ù–ï –ü–û–í–ï–†–ò–®–¨
- –ü—É—Å—Ç—ã–µ —Å–ª–æ–≤–∞: –ò–ú–ü–ï–†–ò–Ø, –í–°–Å, –ü–û–õ–ù–û–°–¢–¨–Æ (–±–µ–∑ —Ü–∏—Ñ—Ä)

–†–ê–ó–†–ï–®–ï–ù–û (–≤–º–µ—Å—Ç–æ –∫–ª–∏–∫–±–µ–π—Ç–∞):
- "–º–∞—Å—à—Ç–∞–±—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ç—Ä—É–¥–Ω–æ –æ—Å–æ–∑–Ω–∞—Ç—å"
- "—ç—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç –Ω–µ—Ä–µ–∞–ª—å–Ω–æ"
- "—á—Ç–æ –∏–∑–º–µ–Ω–∏—Ç—Å—è"
- "–∫–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç"
- "–Ω–µ–≤–µ—Ä–æ—è—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã"

–§–û–†–ú–ê–¢:
- 1-3 —Å—Ç—Ä–æ–∫–∏
- –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ":" –∏–ª–∏ "‚Äî" –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
- –ë—Ä–µ–Ω–¥—ã/–∏–º–µ–Ω–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º (SpaceX, Tesla, Ambani)
- –í–∞–ª—é—Ç–∞: billion ‚Üí –º–ª—Ä–¥., million ‚Üí –º–ª–Ω.
= –ò—Å–ø–æ–ª—å–∑—É–π –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞, –ë–ï–ó –∫–∞–≤—ã—á–µ–∫ –∏ —Ç–æ—á–∫–∏ –≤ –∫–æ–Ω—Ü–µ.
"""

        resp = openai.ChatCompletion.create(
            model="gpt-4.1",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"–°–¥–µ–ª–∞–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –æ–±–ª–æ–∂–∫–∏: {clean_text}"},
            ],
            temperature=0.2,
            max_tokens=120,
        )

        translated = resp.choices[0].message.content.strip()

        translated = translated.strip().strip('"').strip("'").strip()
        translated = translated.rstrip(".")
        lines = [ln.strip() for ln in translated.splitlines() if ln.strip()]
        if len(lines) > 3:
            lines = lines[:3]
        translated = "\n".join(lines)

        logger.info(f"‚úÖ –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {translated}")
        return translated

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ OpenAI –ø–µ—Ä–µ–≤–æ–¥–∞: {e}")
        return text


# ---------------------------------------------------------------------
# OpenCV fallback
# ---------------------------------------------------------------------
def opencv_fallback(image_bgr: np.ndarray, mask_u8: np.ndarray) -> np.ndarray:
    """–ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –±–µ–∑ Replicate."""
    if mask_u8.dtype != np.uint8:
        mask_u8 = mask_u8.astype(np.uint8)

    result = image_bgr.copy()

    blurred = cv2.GaussianBlur(image_bgr, (0, 0), sigmaX=OPENCV_BLUR_SIGMA, sigmaY=OPENCV_BLUR_SIGMA)
    result[mask_u8 == 255] = blurred[mask_u8 == 255]

    try:
        result = cv2.inpaint(result, mask_u8, inpaintRadius=OPENCV_INPAINT_RADIUS, flags=cv2.INPAINT_TELEA)
    except Exception:
        pass

    logger.info("‚úÖ OpenCV fallback (blur + light inpaint)")
    return result


# ---------------------------------------------------------------------
# Replicate FLUX Fill
# ---------------------------------------------------------------------
def flux_inpaint(image_bgr: np.ndarray, mask_u8: np.ndarray) -> np.ndarray:
    if mask_u8.dtype != np.uint8:
        mask_u8 = mask_u8.astype(np.uint8)

    if not REPLICATE_API_TOKEN:
        logger.warning("‚ö†Ô∏è REPLICATE_API_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Üí fallback OpenCV")
        return opencv_fallback(image_bgr, mask_u8)

    try:
        import replicate
        client = replicate.Client(api_token=REPLICATE_API_TOKEN)

        logger.info(f"üöÄ Replicate inpaint: LaMa")

        rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
        pil_img = Image.fromarray(rgb)
        img_buf = BytesIO()
        pil_img.save(img_buf, format="PNG", compress_level=0)
        img_buf.seek(0)

        pil_mask = Image.fromarray(mask_u8, mode="L")
        mask_buf = BytesIO()
        pil_mask.save(mask_buf, format="PNG", compress_level=0)
        mask_buf.seek(0)

        # üëá –ó–ê–ú–ï–ù–ò–¢–¨ –ó–î–ï–°–¨
        output = client.run(
            "allenhooo/lama:cdac78a1bec5b23c07fd29692fb70baa513ea403a39e643c48ec5edadb15fe72",
            input={
                "image": img_buf,
                "mask": mask_buf
            }
        )
        # üëÜ –î–û –°–Æ–î–ê

        # –î–∞–ª—å—à–µ –∫–æ–¥ –æ—Å—Ç–∞—ë—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        if isinstance(output, str):
            r = requests.get(output, timeout=REPLICATE_HTTP_TIMEOUT)
            r.raise_for_status()
            result_bytes = r.content
        elif isinstance(output, list) and output:
            r = requests.get(output[0], timeout=REPLICATE_HTTP_TIMEOUT)
            r.raise_for_status()
            result_bytes = r.content
        elif hasattr(output, "read"):
            result_bytes = output.read()
        else:
            logger.error(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç output")
            return opencv_fallback(image_bgr, mask_u8)

        out_pil = Image.open(BytesIO(result_bytes)).convert("RGB")
        out_rgb = np.array(out_pil)
        out_bgr = cv2.cvtColor(out_rgb, cv2.COLOR_RGB2BGR)

        if out_bgr.shape[:2] != image_bgr.shape[:2]:
            logger.warning("‚ö†Ô∏è Replicate –∏–∑–º–µ–Ω–∏–ª —Ä–∞–∑–º–µ—Ä ‚Üí —Ä–µ—Å–∞–π–∑ –æ–±—Ä–∞—Ç–Ω–æ")
            out_bgr = cv2.resize(out_bgr, (image_bgr.shape[1], image_bgr.shape[0]), interpolation=cv2.INTER_LANCZOS4)

        if FORCE_PRESERVE_OUTSIDE_MASK:
            out_bgr = _composite_by_mask(image_bgr, out_bgr, mask_u8)

        logger.info("‚úÖ LaMa inpaint OK")
        return out_bgr

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ Replicate inpaint: {e}")
        return opencv_fallback(image_bgr, mask_u8)

def _composite_by_mask(original_bgr: np.ndarray, edited_bgr: np.ndarray, mask_u8: np.ndarray) -> np.ndarray:
    """–°–º–µ—à–∏–≤–∞–Ω–∏–µ –ø–æ –º–∞—Å–∫–µ."""
    m = (mask_u8.astype(np.float32) / 255.0)[:, :, None]
    out = (original_bgr.astype(np.float32) * (1.0 - m) + edited_bgr.astype(np.float32) * m)
    return np.clip(out, 0, 255).astype(np.uint8)

def flux_kontext_inpaint(image: np.ndarray, mask: np.ndarray) -> np.ndarray:
    """ALIAS –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ (—Å—Ç–∞—Ä–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ)."""
    return flux_inpaint(image, mask)


# ---------------------------------------------------------------------
# –ì—Ä–∞–¥–∏–µ–Ω—Ç
# ---------------------------------------------------------------------
def create_gradient_layer(width: int, height: int,
                          gradient_height_percent: int) -> Image.Image:
    """–°–æ–∑–¥–∞—ë—Ç —á–µ—Ä–Ω—ã–π –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç —Å–Ω–∏–∑—É –≤–≤–µ—Ä—Ö (Instagram-—Å—Ç–∏–ª—å)."""
    
    grad_h = int(height * gradient_height_percent / 100)
    start_row = height - grad_h
    
    alpha = np.zeros(height, dtype=np.float32)
    
    for i in range(height):
        if i < start_row:
            alpha[i] = 0.0
        else:
            t = (height - 1 - i) / float(grad_h)
            
            if t <= GRADIENT_SOLID_FRACTION:
                alpha[i] = 1.0
            else:
                t_norm = (t - GRADIENT_SOLID_FRACTION) / (1.0 - GRADIENT_SOLID_FRACTION)
                alpha[i] = 1.0 - (t_norm ** GRADIENT_TRANSITION_CURVE)
    
    alpha_u8 = (alpha * 255).astype(np.uint8)
    
    alpha_2d = np.tile(alpha_u8[:, None], (1, width))
    ksize_y = int(GRADIENT_BLUR_SIGMA * 6) | 1
    alpha_blurred = cv2.GaussianBlur(alpha_2d, (1, ksize_y), sigmaX=0, sigmaY=GRADIENT_BLUR_SIGMA)
    
    rgba = np.zeros((height, width, 4), dtype=np.uint8)
    rgba[:, :, 3] = alpha_blurred
    
    logger.info(f"‚ú® –ì—Ä–∞–¥–∏–µ–Ω—Ç: {gradient_height_percent}%, solid={GRADIENT_SOLID_FRACTION*100}%, blur={GRADIENT_BLUR_SIGMA}")
    return Image.fromarray(rgba, mode="RGBA")

# ---------------------------------------------------------------------
# –¢–µ–∫—Å—Ç: –ø–æ–¥–±–æ—Ä —Ä–∞–∑–º–µ—Ä–∞ –∏ –æ—Ç—Ä–∏—Å–æ–≤–∫–∞ —Å–æ "stretch"
# ---------------------------------------------------------------------
def calculate_adaptive_font_size(text: str, font_path: str, max_width: int,
                                 initial_size: int, min_size: int = FONT_SIZE_MIN,
                                 stretch_width: float = TEXT_STRETCH_WIDTH) -> tuple:
    """–ê–≤—Ç–æ–ø–æ–¥–±–æ—Ä —Ä–∞–∑–º–µ—Ä–∞ —à—Ä–∏—Ñ—Ç–∞. Greedy –ø–µ—Ä–µ–Ω–æ—Å."""
    text = (text or "").strip()
    if not text:
        font = ImageFont.truetype(font_path, int(min_size))
        return int(min_size), font, [""]

    words = text.split()
    if not words:
        font = ImageFont.truetype(font_path, int(min_size))
        return int(min_size), font, [text]

    size = int(initial_size)
    while size >= int(min_size):
        try:
            font = ImageFont.truetype(font_path, int(size))
            lines = _wrap_greedy(words, font, max_width, stretch_width)
            if lines:
                return int(size), font, lines
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —à—Ä–∏—Ñ—Ç–∞ {size}: {e}")
        size -= 2

    font = ImageFont.truetype(font_path, int(min_size))
    return int(min_size), font, [text]


def _wrap_greedy(words: list, font: ImageFont.FreeTypeFont, max_width: int, stretch: float) -> list:
    """Greedy –ø–µ—Ä–µ–Ω–æ—Å: –¥–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–∞ –ø–æ–∫–∞ –≤–ª–µ–∑–∞—é—Ç."""
    if not words:
        return []
    
    space_w = max(1, _text_width_px(font, " "))
    lines = []
    current = []
    current_w = 0
    
    for w in words:
        w_width = _text_width_px(font, w)
        test_w = current_w + (space_w if current else 0) + w_width
        
        if current and int(test_w * stretch) > max_width:
            lines.append(" ".join(current))
            current = [w]
            current_w = w_width
        else:
            current.append(w)
            current_w = test_w
    
    if current:
        lines.append(" ".join(current))
    
    return lines if lines else []


def _text_width_px(font: ImageFont.FreeTypeFont, text: str) -> int:
    """–®–∏—Ä–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ –≤ –ø–∏–∫—Å–µ–ª—è—Ö."""
    bb = font.getbbox(text)
    return int(bb[2] - bb[0])


def draw_text_with_stretch(base_image: Image.Image,
                           x: int, y: int,
                           text: str,
                           font: ImageFont.FreeTypeFont,
                           fill_color: tuple,
                           outline_color: tuple,
                           stretch_width: float = TEXT_STRETCH_WIDTH,
                           stretch_height: float = TEXT_STRETCH_HEIGHT,
                           shadow_offset: int = TEXT_SHADOW_OFFSET) -> int:
    """–†–∏—Å—É–µ—Ç —Ç–µ–∫—Å—Ç —Å —Ç–µ–Ω—å—é+–æ–±–≤–æ–¥–∫–æ–π, –∑–∞—Ç–µ–º —Ä–∞—Å—Ç—è–≥–∏–≤–∞–µ—Ç."""
    bbox = font.getbbox(text)
    tw = bbox[2] - bbox[0]
    th = bbox[3] - bbox[1]

    pad = max(6, shadow_offset + TEXT_OUTLINE_THICKNESS * 2)
    temp_w = int(tw * (stretch_width + 1.0)) + pad * 2
    temp_h = int(th * (stretch_height + 1.0)) + pad * 2

    temp = Image.new("RGBA", (temp_w, temp_h), (0, 0, 0, 0))
    d = ImageDraw.Draw(temp)

    tx, ty = pad, pad

    d.text((tx + shadow_offset, ty + shadow_offset), text, font=font, fill=(0, 0, 0, 128))

    for t in range(int(TEXT_OUTLINE_THICKNESS)):
        r = t + 1
        for dx, dy in [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]:
            d.text((tx + dx * r, ty + dy * r), text, font=font, fill=outline_color)

    d.text((tx, ty), text, font=font, fill=fill_color)

    bb = temp.getbbox()
    if not bb:
        return th

    crop = temp.crop(bb)
    sw = max(1, int(crop.width * stretch_width))
    sh = max(1, int(crop.height * stretch_height))
    crop = crop.resize((sw, sh), Image.Resampling.LANCZOS)

    base_image.paste(crop, (x, y), crop)
    return sh


def _estimate_fixed_line_height(font: ImageFont.FreeTypeFont) -> int:
    """–§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤—ã—Å–æ—Ç–∞ —Å—Ç—Ä–æ–∫–∏."""
    try:
        ascent, descent = font.getmetrics()
        base = int((ascent + descent) * TEXT_STRETCH_HEIGHT)
    except Exception:
        base = int(font.size * TEXT_STRETCH_HEIGHT)
    pad = max(6, TEXT_SHADOW_OFFSET + int(TEXT_OUTLINE_THICKNESS) * 2)
    return base + pad


# ---------------------------------------------------------------------
# –†–ï–ù–î–ï–†–´ –†–ï–ñ–ò–ú–û–í
# ---------------------------------------------------------------------
def render_mode1_logo(image: Image.Image, title_translated: str) -> Image.Image:
    """–†–µ–∂–∏–º 1: –õ–æ–≥–æ + –ª–∏–Ω–∏–∏ + –∑–∞–≥–æ–ª–æ–≤–æ–∫ (UPPERCASE)."""
    image = image.convert("RGBA")
    draw = ImageDraw.Draw(image, "RGBA")
    width, height = image.size
    max_text_width = int(width * TEXT_WIDTH_PERCENT)

    title = (title_translated or "").upper()
    _, title_font, title_lines = calculate_adaptive_font_size(
        title, FONT_PATH, max_text_width, FONT_SIZE_MODE1, stretch_width=TEXT_STRETCH_WIDTH
    )

    line_h = _estimate_fixed_line_height(title_font)
    total_title_h = line_h * len(title_lines) + max(0, (len(title_lines) - 1) * LINE_SPACING)

    logo_font = ImageFont.truetype(FONT_PATH, FONT_SIZE_LOGO)
    logo_text = "@neurostep.media"
    bb = logo_font.getbbox(logo_text)
    logo_w = bb[2] - bb[0]
    logo_h = bb[3] - bb[1]

    total_h = logo_h + SPACING_LOGO_TO_TITLE + total_title_h
    start_y = height - SPACING_BOTTOM - total_h

    logo_x = (width - logo_w) // 2
    logo_y = start_y

    line_y = logo_y + logo_h // 2
    line_left_start = logo_x - LOGO_LINE_LENGTH - 10
    line_right_start = logo_x + logo_w + 10

    draw.line([(line_left_start, line_y), (line_left_start + LOGO_LINE_LENGTH, line_y)], fill=COLOR_TURQUOISE, width=LOGO_LINE_THICKNESS_PX)
    draw.line([(line_right_start, line_y), (line_right_start + LOGO_LINE_LENGTH, line_y)], fill=COLOR_TURQUOISE, width=LOGO_LINE_THICKNESS_PX)
    draw.text((logo_x, logo_y), logo_text, font=logo_font, fill=COLOR_WHITE)

    cur_y = start_y + logo_h + SPACING_LOGO_TO_TITLE
    block_left = (width - max_text_width) // 2
    
    for i, ln in enumerate(title_lines):
        line_w = int(_text_width_px(title_font, ln) * TEXT_STRETCH_WIDTH)
        line_x = block_left + (max_text_width - line_w) // 2
        draw_text_with_stretch(image, line_x, cur_y, ln, title_font, COLOR_TURQUOISE, COLOR_OUTLINE)
        cur_y += line_h
        if i < len(title_lines) - 1:
            cur_y += LINE_SPACING

    return image


def render_mode2_text(image: Image.Image, title_translated: str) -> Image.Image:
    """–†–µ–∂–∏–º 2: —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ (UPPERCASE)."""
    image = image.convert("RGBA")
    width, height = image.size
    max_text_width = int(width * TEXT_WIDTH_PERCENT)

    title = (title_translated or "").upper()
    _, title_font, title_lines = calculate_adaptive_font_size(
        title, FONT_PATH, max_text_width, FONT_SIZE_MODE2, stretch_width=TEXT_STRETCH_WIDTH
    )

    line_h = _estimate_fixed_line_height(title_font)
    total_h = line_h * len(title_lines) + max(0, (len(title_lines) - 1) * LINE_SPACING)

    start_y = height - SPACING_BOTTOM - total_h
    cur_y = start_y
    block_left = (width - max_text_width) // 2

    for i, ln in enumerate(title_lines):
        line_w = int(_text_width_px(title_font, ln) * TEXT_STRETCH_WIDTH)
        line_x = block_left + (max_text_width - line_w) // 2
        draw_text_with_stretch(image, line_x, cur_y, ln, title_font, COLOR_TURQUOISE, COLOR_OUTLINE)
        cur_y += line_h
        if i < len(title_lines) - 1:
            cur_y += LINE_SPACING

    return image


def render_mode3_content(image: Image.Image, title_translated: str, subtitle_translated: str) -> Image.Image:
    """–†–µ–∂–∏–º 3: –∑–∞–≥–æ–ª–æ–≤–æ–∫ + –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫ (–æ–±–∞ UPPERCASE)."""
    image = image.convert("RGBA")
    width, height = image.size
    max_text_width = int(width * TEXT_WIDTH_PERCENT)

    title = (title_translated or "").upper()
    subtitle = (subtitle_translated or "").upper()

    title_size, title_font, title_lines = calculate_adaptive_font_size(
        title, FONT_PATH, max_text_width, FONT_SIZE_MODE3_TITLE, stretch_width=TEXT_STRETCH_WIDTH
    )

    subtitle_initial = int(title_size * 0.80)
    _, subtitle_font, subtitle_lines = calculate_adaptive_font_size(
        subtitle, FONT_PATH, max_text_width, subtitle_initial, stretch_width=TEXT_STRETCH_WIDTH
    )

    title_line_h = _estimate_fixed_line_height(title_font)
    sub_line_h = _estimate_fixed_line_height(subtitle_font)

    total_title_h = title_line_h * len(title_lines) + max(0, (len(title_lines) - 1) * LINE_SPACING)
    total_sub_h = sub_line_h * len(subtitle_lines) + max(0, (len(subtitle_lines) - 1) * LINE_SPACING)

    total_h = total_title_h + SPACING_TITLE_TO_SUBTITLE + total_sub_h
    start_y = height - SPACING_BOTTOM_MODE3 - total_h

    cur_y = start_y
    block_left = (width - max_text_width) // 2

    for i, ln in enumerate(title_lines):
        line_w = int(_text_width_px(title_font, ln) * TEXT_STRETCH_WIDTH)
        line_x = block_left + (max_text_width - line_w) // 2
        draw_text_with_stretch(image, line_x, cur_y, ln, title_font, COLOR_TURQUOISE, COLOR_OUTLINE)
        cur_y += title_line_h
        if i < len(title_lines) - 1:
            cur_y += LINE_SPACING

    cur_y += SPACING_TITLE_TO_SUBTITLE

    for i, ln in enumerate(subtitle_lines):
        line_w = int(_text_width_px(subtitle_font, ln) * TEXT_STRETCH_WIDTH)
        line_x = block_left + (max_text_width - line_w) // 2
        draw_text_with_stretch(image, line_x, cur_y, ln, subtitle_font, COLOR_WHITE, COLOR_OUTLINE)
        cur_y += sub_line_h
        if i < len(subtitle_lines) - 1:
            cur_y += LINE_SPACING

    return image


# ---------------------------------------------------------------------
# –û–°–ù–û–í–ù–û–ô WORKFLOW
# ---------------------------------------------------------------------
def process_full_workflow(image_bgr: np.ndarray, mode: int) -> tuple:
    """–ü–æ–ª–Ω—ã–π workflow –¥–ª—è —Ä–µ–∂–∏–º–æ–≤ 1,2,3."""
    logger.info("=" * 60)
    logger.info(f"üöÄ –ü–û–õ–ù–´–ô WORKFLOW - –†–ï–ñ–ò–ú {mode}")
    logger.info("=" * 60)

    h, w = image_bgr.shape[:2]

    logger.info("üìã –®–ê–ì 1: OCR (Google Vision)")
    ocr = google_vision_ocr(image_bgr, crop_bottom_percent=OCR_BOTTOM_PERCENT)
    if not ocr["text"]:
        logger.warning("‚ö†Ô∏è –¢–µ–∫—Å—Ç –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω")
        return image_bgr, ocr

    logger.info("üìã –®–ê–ì 2: –ú–∞—Å–∫–∞ (–Ω–∏–∂–Ω–∏–µ %)")
    mask = np.zeros((h, w), dtype=np.uint8)
    mask_start = int(h * (1 - MASK_BOTTOM_PERCENT / 100))
    mask[mask_start:, :] = 255
    logger.info(f"üìê –ú–∞—Å–∫–∞: —Å—Ç—Ä–æ–∫–∏ {mask_start}-{h} (–Ω–∏–∂–Ω–∏–µ {MASK_BOTTOM_PERCENT}%)")

    logger.info("üìã –®–ê–ì 3: Inpaint (Replicate FLUX Fill)")
    clean_bgr = flux_inpaint(image_bgr, mask)

    logger.info("üìã –®–ê–ì 4: –ü–µ—Ä–µ–≤–æ–¥ (OpenAI)")
    title_translated, subtitle_translated = "", ""

    if mode == 3:
        lines = ocr["lines"]
        if len(lines) >= 2:
            title = " ".join(lines[:-1])
            subtitle = lines[-1]
        else:
            title, subtitle = ocr["text"], ""

        title_translated = openai_translate(title)
        subtitle_translated = openai_translate(subtitle) if subtitle else ""
    else:
        title_translated = openai_translate(ocr["text"])

    logger.info("üìã –®–ê–ì 5: –ì—Ä–∞–¥–∏–µ–Ω—Ç")
    clean_rgb = cv2.cvtColor(clean_bgr, cv2.COLOR_BGR2RGB)
    pil = Image.fromarray(clean_rgb).convert("RGBA")

    if submode == 3:
        grad = create_gradient_layer(pil.size[0], pil.size[1], gradient_height_percent=GRADIENT_HEIGHT_MODE3)
    else:
        grad = create_gradient_layer(pil.size[0], pil.size[1], gradient_height_percent=GRADIENT_HEIGHT_MODE12)
    pil = Image.alpha_composite(pil, grad)
    logger.info("‚úÖ –ì—Ä–∞–¥–∏–µ–Ω—Ç –Ω–∞–ª–æ–∂–µ–Ω")

    logger.info("üìã –®–ê–ì 6: –†–µ–Ω–¥–µ—Ä —Ç–µ–∫—Å—Ç–∞")
    if mode == 1:
        pil = render_mode1_logo(pil, title_translated)
    elif mode == 2:
        pil = render_mode2_text(pil, title_translated)
    elif mode == 3:
        pil = render_mode3_content(pil, title_translated, subtitle_translated)
    else:
        logger.warning(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º {mode} ‚Üí –ø—Ä–æ–ø—É—Å–∫–∞—é —Ä–µ–Ω–¥–µ—Ä")

    out_rgb = np.array(pil.convert("RGB"))
    out_bgr = cv2.cvtColor(out_rgb, cv2.COLOR_RGB2BGR)

    logger.info("=" * 60)
    logger.info("‚úÖ WORKFLOW –ó–ê–í–ï–†–®–Å–ù!")
    logger.info("=" * 60)
    return out_bgr, ocr


def replicate_inpaint(image: np.ndarray, mask: np.ndarray) -> np.ndarray:
    """–ê–ª–∏–∞—Å –¥–ª—è inpaint."""
    return flux_inpaint(image, mask)
