# lama_integration.py
"""
–ü–æ–ª–Ω—ã–π workflow –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:
1) OCR (Google Vision) –ø–æ –Ω–∏–∂–Ω–µ–π —á–∞—Å—Ç–∏
2) Inpaint (Replicate FLUX Fill) –¢–û–õ–¨–ö–û –ø–æ –º–∞—Å–∫–µ (–Ω–∏–∂–Ω–∏–µ N%)
3) –ü–µ—Ä–µ–≤–æ–¥ (OpenAI)
4) –ù–∞–ª–æ–∂–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ (—Ç–æ—á–Ω–æ –Ω–∞ –Ω–∏–∂–Ω–∏–µ N%)
5) –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞/–ª–∏–Ω–∏–π/–ª–æ–≥–æ –ø–æ —Ä–µ–∂–∏–º–∞–º

–í–ê–ñ–ù–û:
- –í–∞—à–µ "–º—ã–ª–æ" –≤ –ª–æ–≥–µ –ø–æ—è–≤–∏–ª–æ—Å—å –ø–æ—Ç–æ–º—É —á—Ç–æ Replicate –≤–µ—Ä–Ω—É–ª 401 Invalid token ‚Üí —Å—Ä–∞–±–æ—Ç–∞–ª OpenCV fallback (–æ–Ω –≤—Å–µ–≥–¥–∞ –º–∞–∂–µ—Ç –Ω–∞ –±–æ–ª—å—à–æ–π –º–∞—Å–∫–µ).
- –ú–æ–¥–µ–ª—å flux-kontext-pro –ù–ï –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç mask, –ø–æ—ç—Ç–æ–º—É –º–æ–≥–ª–∞ ‚Äú–ª–µ–∑—Ç—å‚Äù –∑–∞ –ø—Ä–µ–¥–µ–ª—ã –æ–±–ª–∞—Å—Ç–∏. –î–ª—è –º–∞—Å–æ—á–Ω–æ–≥–æ –∏–Ω–ø–µ–π–Ω—Ç–∞ –Ω—É–∂–Ω–æ flux-fill-pro.
"""

# ============== –ò–ú–ü–û–†–¢–´ ==============
import os
import logging
import base64
from io import BytesIO

import numpy as np
import cv2
import requests
from PIL import Image, ImageDraw, ImageFont

import openai

logger = logging.getLogger(__name__)

"""
==============================================
–ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø –ë–´–°–¢–†–û–ô –†–£–ß–ù–û–ô –ü–†–ê–í–ö–ò
(–≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –≤—ã–Ω–µ—Å–µ–Ω—ã —Å—é–¥–∞)
==============================================
"""

# ============== API –ö–õ–Æ–ß–ò ==============
REPLICATE_API_TOKEN = os.getenv("REPLICATE_API_TOKEN", "").strip()
GOOGLE_VISION_API_KEY = os.getenv("GOOGLE_VISION_API_KEY", "").strip()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()

# ============== REPLICATE / FLUX (INPAINT) ==============
# –ú–û–î–ï–õ–¨ –î–õ–Ø –ú–ê–°–ö–û–í–û–ì–û INPAINT:
# flux-kontext-pro ‚Äî —ç—Ç–æ ‚Äúedit‚Äù, –±–µ–∑ –º–∞—Å–∫–∏; –¥–ª—è –º–∞—Å–∫–∏ –Ω—É–∂–Ω–æ flux-fill-pro.
REPLICATE_MODEL = os.getenv("REPLICATE_MODEL", "black-forest-labs/flux-fill-pro").strip()  # –ø–æ–º–µ–Ω—è—Ç—å –µ—Å–ª–∏ –Ω–∞–¥–æ
FLUX_STEPS = int(os.getenv("FLUX_STEPS", "50"))      # 15..50 (–±–æ–ª—å—à–µ = –¥–µ—Ç–∞–ª—å–Ω–µ–µ, –º–µ–¥–ª–µ–Ω–Ω–µ–µ; —É –º–æ–¥–µ–ª–∏ max=50)
FLUX_GUIDANCE = float(os.getenv("FLUX_GUIDANCE", "60"))  # 1.5..100 (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —É –º–æ–¥–µ–ª–∏ 60; –≤—ã—à–µ = —Å–∏–ª—å–Ω–µ–µ —Å–ª–µ–¥—É–µ—Ç –ø—Ä–æ–º–ø—Ç—É, –Ω–æ –º–æ–∂–µ—Ç –ø–æ—Ä—Ç–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ)
FLUX_OUTPUT_FORMAT = os.getenv("FLUX_OUTPUT_FORMAT", "png")  # png = –±–µ–∑ –ø–æ—Ç–µ—Ä—å
FLUX_PROMPT_UPSAMPLING = False  # True = —Ç–≤–æ—Ä—á–µ—Å–∫–∏ ‚Äú–¥–æ–¥—É–º–∞–µ—Ç‚Äù –ø—Ä–æ–º–ø—Ç, –æ–±—ã—á–Ω–æ –Ω–µ –Ω–∞–¥–æ –¥–ª—è —á–∏—Å—Ç–∫–∏
REPLICATE_HTTP_TIMEOUT = int(os.getenv("REPLICATE_HTTP_TIMEOUT", "120"))  # —Ç–∞–π–º–∞—É—Ç —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

# –ñ—ë—Å—Ç–∫–∞—è –≥–∞—Ä–∞–Ω—Ç–∏—è: ‚Äú–≤—Å—ë –≤–Ω–µ –º–∞—Å–∫–∏ –ù–ï –º–µ–Ω—è–µ–º‚Äù, –¥–∞–∂–µ –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –ø–æ–ø—ã—Ç–∞–ª–∞—Å—å
FORCE_PRESERVE_OUTSIDE_MASK = True

# ============== –¶–í–ï–¢–ê ==============
COLOR_TURQUOISE = (0, 206, 209)  # –ë–∏—Ä—é–∑–æ–≤—ã–π –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
COLOR_WHITE = (255, 255, 255)    # –ë–µ–ª—ã–π –¥–ª—è –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–æ–≤/–ª–æ–≥–æ
COLOR_OUTLINE = (60, 60, 60)     # –û–±–≤–æ–¥–∫–∞ —Ç–µ–∫—Å—Ç–∞ (#3C3C3C)

# ============== –†–ê–ó–ú–ï–†–´ –®–†–ò–§–¢–û–í ==============
FONT_SIZE_MODE1 = 54             # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –≤ —Ä–µ–∂–∏–º–µ 1 (–ª–æ–≥–æ)
FONT_SIZE_MODE2 = 52             # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –≤ —Ä–µ–∂–∏–º–µ 2 (—Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç)
FONT_SIZE_MODE3_TITLE = 52       # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –≤ —Ä–µ–∂–∏–º–µ 3
FONT_SIZE_MODE3_SUBTITLE = 50    # –ü–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤ —Ä–µ–∂–∏–º–µ 3
FONT_SIZE_LOGO = 24              # –†–∞–∑–º–µ—Ä @neurostep.media
FONT_SIZE_MIN = 44               # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø—Ä–∏ –∞–≤—Ç–æ–ø–æ–¥–±–æ—Ä–µ (—É–º–µ–Ω—å—à–∏—Ç—å = –º–µ–ª—å—á–µ)

# ============== –û–¢–°–¢–£–ü–´ –ò –†–ê–°–°–¢–û–Ø–ù–ò–Ø ==============
SPACING_BOTTOM = 120             # –û—Ç—Å—Ç—É–ø —Å–Ω–∏–∑—É –¥–æ –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏
SPACING_LOGO_TO_TITLE = 6        # –ú–µ–∂–¥—É –ª–æ–≥–æ—Ç–∏–ø–æ–º –∏ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
SPACING_TITLE_TO_SUBTITLE = 10   # –ú–µ–∂–¥—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–º –∏ –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–æ–º
LINE_SPACING = 12                # –ú–µ–∂–¥—É —Å—Ç—Ä–æ–∫–∞–º–∏
LOGO_LINE_LENGTH = 300           # –î–ª–∏–Ω–∞ –ª–∏–Ω–∏–π –≤–æ–∑–ª–µ –ª–æ–≥–æ
LOGO_LINE_THICKNESS_PX = 2   # —Ç–æ–ª—â–∏–Ω–∞ –ø–æ–ª–æ—Å –≤–æ–∑–ª–µ –ª–æ–≥–æ—Ç–∏–ø–∞ (@neurostep.media)

# ============== –ú–ê–°–ö–ê / OCR ==============
MASK_BOTTOM_PERCENT = 35         # –°–∫–æ–ª—å–∫–æ % —Å–Ω–∏–∑—É —á–∏—Å—Ç–∏–º (–º–∞—Å–∫–∞)
OCR_BOTTOM_PERCENT = 35          # OCR –∑–æ–Ω–∞ —Å–Ω–∏–∑—É (–¥–µ—Ä–∂–∞—Ç—å —Ä–∞–≤–Ω–æ–π –º–∞—Å–∫–µ)

# ============== –ì–†–ê–î–ò–ï–ù–¢ ==============
# –ì—Ä–∞–¥–∏–µ–Ω—Ç –ø–æ–∫—Ä—ã–≤–∞–µ—Ç –¢–û–õ–¨–ö–û –Ω–∏–∂–Ω–∏–µ MASK_BOTTOM_PERCENT, –∫–∞–∫ –≤—ã –æ–ø–∏—Å–∞–ª–∏
GRADIENT_COVER_PERCENT = 35      # –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –æ—Ç–¥–µ–ª—å–Ω–æ ‚Äî –º–µ–Ω—è–π—Ç–µ; –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é = 35%
GRADIENT_SOLID_FRACTION = 0.50   # –∫–∞–∫–∞—è —á–∞—Å—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ —Å–Ω–∏–∑—É 100% –Ω–µ–ø—Ä–æ–∑—Ä–∞—á–Ω–∞—è (0.5 = –Ω–∏–∂–Ω—è—è –ø–æ–ª–æ–≤–∏–Ω–∞)
GRADIENT_SOLID_RAISE_PX = int(os.getenv("GRADIENT_SOLID_RAISE_PX", "120"))  # ‚Üë –≥—Ä–∞–Ω–∏—Ü—É "—á—ë—Ä–Ω–æ–π –æ—Å–Ω–æ–≤—ã" –Ω–∞ N px (—Å–∫—Ä—ã—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã)
GRADIENT_INTENSITY_CURVE = 1.0   # –ø–ª–∞–≤–Ω–æ—Å—Ç—å –≤ –≤–µ—Ä—Ö–Ω–µ–π –ø–æ–ª–æ–≤–∏–Ω–µ (–±–æ–ª—å—à–µ = —Ä–µ–∑—á–µ –ø–µ—Ä–µ—Ö–æ–¥)

# ============== –†–ê–°–¢–Ø–ñ–ï–ù–ò–ï –¢–ï–ö–°–¢–ê ==============
TEXT_STRETCH_HEIGHT = 1.6       # +25% –ø–æ –≤—ã—Å–æ—Ç–µ
TEXT_STRETCH_WIDTH = 1.2        # +10% –ø–æ —à–∏—Ä–∏–Ω–µ

# ============== –¢–ï–ù–ò / –û–ë–í–û–î–ö–ò ==============
TEXT_SHADOW_OFFSET = 2           # –°–º–µ—â–µ–Ω–∏–µ —Ç–µ–Ω–∏ (–±–æ–ª—å—à–µ = –¥–∞–ª—å—à–µ —Ç–µ–Ω—å)
TEXT_OUTLINE_THICKNESS = 1       # –¢–æ–ª—â–∏–Ω–∞ –æ–±–≤–æ–¥–∫–∏ (—É–≤–µ–ª–∏—á–∏—Ç—å = –∂–∏—Ä–Ω–µ–µ)

# ============== –ë–õ–û–ö –¢–ï–ö–°–¢–ê ==============
TEXT_WIDTH_PERCENT = 0.90        # –®–∏—Ä–∏–Ω–∞ –±–ª–æ–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç —à–∏—Ä–∏–Ω—ã –∫–∞—Ä—Ç–∏–Ω–∫–∏

# ============== OPENCV FALLBACK ==============
# –ï—Å–ª–∏ Replicate –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω/—É–ø–∞–ª, –≤–∫–ª—é—á–∞–µ—Ç—Å—è fallback. –ù–∞ –±–æ–ª—å—à–æ–π –º–∞—Å–∫–µ –∏–¥–µ–∞–ª–∞ –Ω–µ –±—É–¥–µ—Ç.
OPENCV_BLUR_SIGMA = 5            # –ë–ª—é—Ä –≤–Ω—É—Ç—Ä–∏ –º–∞—Å–∫–∏ (–±–æ–ª—å—à–µ = —Å–∏–ª—å–Ω–µ–µ ‚Äú—Å—ä–µ—Å—Ç‚Äù –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã)
OPENCV_INPAINT_RADIUS = 3        # –†–∞–¥–∏—É—Å –∏–Ω–ø–µ–π–Ω—Ç–∞ (–±–æ–ª—å—à–µ = —Å–∏–ª—å–Ω–µ–µ ‚Äú–º–∞–∂–µ—Ç‚Äù)

# ============== –ü–£–¢–¨ –ö –®–†–ò–§–¢–£ ==============
FONT_PATH = os.getenv("FONT_PATH", "/app/fonts/WaffleSoft.otf").strip()

"""
==============================================
–ö–û–ù–ï–¶ –ù–ê–°–¢–†–û–ï–ö
==============================================
"""

openai.api_key = OPENAI_API_KEY


# ---------------------------------------------------------------------
# OCR (Google Vision)
# ---------------------------------------------------------------------
def google_vision_ocr(image_bgr: np.ndarray, crop_bottom_percent: int = OCR_BOTTOM_PERCENT) -> dict:
    """OCR —á–µ—Ä–µ–∑ Google Vision API –ø–æ –Ω–∏–∂–Ω–µ–π —á–∞—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—á—Ç–æ–±—ã –Ω–µ –ª–æ–≤–∏—Ç—å –≤–µ—Å—å –∫–∞–¥—Ä)."""
    if not GOOGLE_VISION_API_KEY:
        logger.warning("‚ö†Ô∏è GOOGLE_VISION_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return {"text": "", "lines": []}

    try:
        h, w = image_bgr.shape[:2]
        crop_start = int(h * (1 - crop_bottom_percent / 100))
        cropped = image_bgr[crop_start:, :]

        logger.info(f"üîç OCR –Ω–∞ {crop_bottom_percent}% —Å–Ω–∏–∑—É (—Å—Ç—Ä–æ–∫–∏ {crop_start}-{h})")

        rgb = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)
        pil_img = Image.fromarray(rgb)
        buf = BytesIO()
        pil_img.save(buf, format="PNG")
        image_base64 = base64.b64encode(buf.getvalue()).decode("utf-8")

        url = f"https://vision.googleapis.com/v1/images:annotate?key={GOOGLE_VISION_API_KEY}"
        payload = {
            "requests": [{
                "image": {"content": image_base64},
                "features": [{"type": "TEXT_DETECTION"}]
            }]
        }

        resp = requests.post(url, json=payload, timeout=30)
        data = resp.json()

        if not data.get("responses"):
            logger.warning("‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ OCR")
            return {"text": "", "lines": []}

        r0 = data["responses"][0]
        ann = r0.get("textAnnotations")
        if not ann:
            logger.warning("‚ö†Ô∏è –¢–µ–∫—Å—Ç –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω")
            return {"text": "", "lines": []}

        full_text = ann[0].get("description", "")
        # –õ–æ–≥–∏ –Ω–µ –ª—é–±—è—Ç \n –≤–Ω—É—Ç—Ä–∏ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ ‚Äî –ø–æ—ç—Ç–æ–º—É lines –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–ø–∏—Å–∫–æ–º
        lines = [ln.strip() for ln in full_text.split("\n") if ln.strip()]

        # –ù–µ–±–æ–ª—å—à–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ç–∏–ø–æ–≤—ã—Ö ‚Äú—Å–ª—É–∂–µ–±–Ω—ã—Ö‚Äù —Å—Ç—Ä–æ–∫, –µ—Å–ª–∏ –æ–Ω–∏ –ø–æ–ø–∞–ª–∏ –≤ OCR
        if lines and lines[0].strip().lower() in {"wealth", "@neurostep.media"}:
            lines = lines[1:]
            full_text = "\n".join(lines)

        logger.info(f"üìù OCR —Å—Ç—Ä–æ–∫–∏: {len(lines)}")
        return {"text": full_text.strip(), "lines": lines}

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ Google Vision OCR: {e}")
        return {"text": "", "lines": []}


# ---------------------------------------------------------------------
# –ü–µ—Ä–µ–≤–æ–¥ (OpenAI)
# ---------------------------------------------------------------------
def openai_translate(text: str) -> str:
    """–ü–µ—Ä–µ–≤–æ–¥ –∏ –∞–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ –°–ù–ì (–∫–æ—Ä–æ—Ç–∫–æ, –ø–æ —Å–º—ã—Å–ª—É, –±–µ–∑ –ª–∏—à–Ω–µ–≥–æ)."""
    if not OPENAI_API_KEY or not text:
        logger.warning("‚ö†Ô∏è OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞")
        return text

    try:
        logger.info(f"üåê –ü–µ—Ä–µ–≤–æ–¥: {text}")

        system_prompt = (
            """–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ –¥–ª—è —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω–æ–π (–°–ù–ì) –∞—É–¥–∏—Ç–æ—Ä–∏–∏.\n"
            "–ü—Ä–∞–≤–∏–ª–∞:\n"
            "1) –ë—Ä–µ–Ω–¥—ã –æ—Å—Ç–∞–≤–ª—è–π –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º (SpaceX, Tesla, Apple)\n"
            "2) –ù–µ –¥–æ—Å–ª–æ–≤–Ω–æ ‚Äî –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä—É—Å—Å–∫–∏–π\n"
            "3) –ö–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ –≤–º–µ—Å—Ç–æ –¥–ª–∏–Ω–Ω—ã—Ö\n"
            "4) billion‚Üí–º–ª—Ä–¥., million‚Üí–º–ª–Ω.\n"
            "5) –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–≤–æ–¥, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π\n"
            "6) –î–µ–ª–∞–π —Ç–µ–∫—Å—Ç –∂–∏–≤—ã–º –∏ –ø–æ–Ω—è—Ç–Ω—ã–º –¥–ª—è –°–ù–ì\n"
            "–ü—Ä–∏–º–µ—Ä:"
            "The Most Expensive Things Humans Have Ever Created" ‚Üí "–°–∞–º—ã–µ –¥–æ—Ä–æ–≥–∏–µ —Ç–≤–æ—Ä–µ–Ω–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å—Ç–≤–∞"
            "SpaceX Starlink Satellite Constellation" ‚Üí "–°–ø—É—Ç–Ω–∏–∫–æ–≤–∞—è —Å–µ—Ç—å SpaceX Starlink"
            "$10 billion" ‚Üí "$10 –º–ª—Ä–¥.\n"
            "We Share Insights That Expand Your View" ‚Üí "–î–µ–ª–∏–º—Å—è –∑–Ω–∞–Ω–∏—è–º–∏, —Ä–∞—Å—à–∏—Ä—è—é—â–∏–º–∏ –∫—Ä—É–≥–æ–∑–æ—Ä"
            "Aircraft" ‚Üí "–ò—Å—Ç—Ä–µ–±–∏—Ç–µ–ª—å\n"
            "Northrop B-2 Spirit" ‚Üí "–°—Ç–µ–ª—Å-–±–æ–º–±–∞—Ä–¥–∏—Ä–æ–≤—â–∏–∫ Northrop B-2 Spirit"
            """    
        )

        # –û—Å—Ç–∞–≤–ª—è—é gpt-4 –∫–∞–∫ –≤ –≤–∞—à–µ–º –∫–æ–¥–µ, —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å –æ–∫—Ä—É–∂–µ–Ω–∏–µ.
        resp = openai.ChatCompletion.create(
            model="gpt-4.1",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"–ü–µ—Ä–µ–≤–µ–¥–∏ –∏ –∞–¥–∞–ø—Ç–∏—Ä—É–π: {text}"},
            ],
            temperature=0.4,
            max_tokens=200,
        )

        translated = resp.choices[0].message.content.strip()
        logger.info(f"‚úÖ –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {translated}")
        return translated

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ OpenAI –ø–µ—Ä–µ–≤–æ–¥–∞: {e}")
        return text


# ---------------------------------------------------------------------
# OpenCV fallback (–∫–æ–≥–¥–∞ Replicate –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)
# ---------------------------------------------------------------------
def opencv_fallback(image_bgr: np.ndarray, mask_u8: np.ndarray) -> np.ndarray:
    """
    –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –±–µ–∑ Replicate.
    –õ–æ–≥–∏–∫–∞: –≤–Ω—É—Ç—Ä–∏ –º–∞—Å–∫–∏ —Ä–∞–∑–º—ã–≤–∞–µ–º + –ª—ë–≥–∫–∏–π inpaint, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ ‚Äú–≥—Ä—è–∑–∏‚Äù.
    """
    if mask_u8.dtype != np.uint8:
        mask_u8 = mask_u8.astype(np.uint8)

    result = image_bgr.copy()

    # –†–∞–∑–º—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –æ–±–ª–∞—Å—Ç—å –º–∞—Å–∫–∏ (—Ç–∞–∫ –º–µ–Ω—å—à–µ ‚Äú–º—ã–ª–∞‚Äù, —á–µ–º —É –ø–æ–ª–Ω–æ–≥–æ inpaint –Ω–∞ –æ–≥—Ä–æ–º–Ω–æ–π –º–∞—Å–∫–µ)
    blurred = cv2.GaussianBlur(image_bgr, (0, 0), sigmaX=OPENCV_BLUR_SIGMA, sigmaY=OPENCV_BLUR_SIGMA)
    result[mask_u8 == 255] = blurred[mask_u8 == 255]

    # –õ—ë–≥–∫–∏–π inpaint –ø–æ–≤–µ—Ä—Ö (—Ä–∞–¥–∏—É—Å –º–∞–ª–µ–Ω—å–∫–∏–π, —á—Ç–æ–±—ã –Ω–µ ‚Äú–ø–ª—ã–ª–∞‚Äù —Ç–µ–∫—Å—Ç—É—Ä–∞)
    try:
        result = cv2.inpaint(result, mask_u8, inpaintRadius=OPENCV_INPAINT_RADIUS, flags=cv2.INPAINT_TELEA)
    except Exception:
        pass

    logger.info("‚úÖ OpenCV fallback (blur + light inpaint)")
    return result


# ---------------------------------------------------------------------
# Replicate FLUX Fill (–º–∞—Å–æ—á–Ω—ã–π inpaint)
# ---------------------------------------------------------------------
def flux_inpaint(image_bgr: np.ndarray, mask_u8: np.ndarray) -> np.ndarray:
    """
    Inpaint —á–µ—Ä–µ–∑ Replicate –Ω–∞ –º–æ–¥–µ–ª–∏ FLUX Fill.
    –ì–∞—Ä–∞–Ω—Ç–∏—è: –µ—Å–ª–∏ FORCE_PRESERVE_OUTSIDE_MASK=True ‚Äî –≤–Ω–µ –º–∞—Å–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –ø–∏–∫—Å–µ–ª—å-–≤-–ø–∏–∫—Å–µ–ª—å.
    """
    if mask_u8.dtype != np.uint8:
        mask_u8 = mask_u8.astype(np.uint8)

    if not REPLICATE_API_TOKEN:
        logger.warning("‚ö†Ô∏è REPLICATE_API_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Üí fallback OpenCV")
        return opencv_fallback(image_bgr, mask_u8)

    try:
        import replicate  # –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç, —á—Ç–æ–±—ã –ø—Ä–æ–µ–∫—Ç —Å—Ç–∞—Ä—Ç–æ–≤–∞–ª –¥–∞–∂–µ –±–µ–∑ replicate –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏

        # –ö–ª–∏–µ–Ω—Ç —Å —è–≤–Ω—ã–º —Ç–æ–∫–µ–Ω–æ–º (–Ω–∞ Railway —Ç–∞–∫ –Ω–∞–¥—ë–∂–Ω–µ–µ)
        client = replicate.Client(api_token=REPLICATE_API_TOKEN)

        logger.info(f"üöÄ Replicate inpaint: {REPLICATE_MODEL}")

        # –í–∞–∂–Ω—ã–π –º–æ–º–µ–Ω—Ç: –º–æ–¥–µ–ª—å —Å–∞–º–∞ –Ω–µ ‚Äú–ø–æ–Ω–∏–º–∞–µ—Ç‚Äù –≤–∞—à—É –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É.
        # –ú—ã –ø—Ä–æ—Å–∏–º —É–¥–∞–ª–∏—Ç—å —Ç–µ–∫—Å—Ç/–ª–∏–Ω–∏–∏/–ª–æ–≥–æ—Ç–∏–ø—ã (–≤–Ω—É—Ç—Ä–∏ –º–∞—Å–∫–∏), –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ñ–æ–Ω, –±–µ–∑ —Ä–∞–∑–º—ã—Ç–∏—è.
        prompt = (
            "Remove all text, decorative lines and logos in the masked region. "
            "Reconstruct the original background naturally with clean, sharp detail. "
            "Match lighting, texture, and perspective. No blur, no smears, no artifacts, no repeating patterns. "
            "Do not change anything outside the mask."
        )

        # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ PNG –±–µ–∑ –ø–æ—Ç–µ—Ä—å
        rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
        pil_img = Image.fromarray(rgb)
        img_buf = BytesIO()
        pil_img.save(img_buf, format="PNG", compress_level=0)
        img_buf.seek(0)

        # –ú–∞—Å–∫–∞ (–±–µ–ª–æ–µ = –∏–Ω–ø–µ–π–Ω—Ç, —á—ë—Ä–Ω–æ–µ = —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å)
        pil_mask = Image.fromarray(mask_u8, mode="L")
        mask_buf = BytesIO()
        pil_mask.save(mask_buf, format="PNG", compress_level=0)
        mask_buf.seek(0)

        # –í–ê–ñ–ù–û: —É flux-fill-pro –ø–æ–ª—è –Ω–∞–∑—ã–≤–∞—é—Ç—Å—è image/mask/steps/guidance (–Ω–µ input_image/num_inference_steps).
        output = client.run(
            REPLICATE_MODEL,
            input={
                "prompt": prompt,
                "image": img_buf,
                "mask": mask_buf,
                "steps": int(np.clip(FLUX_STEPS, 15, 50)),
                "guidance": float(np.clip(FLUX_GUIDANCE, 1.5, 100)),
                "prompt_upsampling": bool(FLUX_PROMPT_UPSAMPLING),
                "output_format": FLUX_OUTPUT_FORMAT,
            },
        )

        # output –æ–±—ã—á–Ω–æ = URL (string)
        if isinstance(output, str):
            r = requests.get(output, timeout=REPLICATE_HTTP_TIMEOUT)
            r.raise_for_status()
            result_bytes = r.content
        elif isinstance(output, list) and output:
            r = requests.get(output[0], timeout=REPLICATE_HTTP_TIMEOUT)
            r.raise_for_status()
            result_bytes = r.content
        elif hasattr(output, "read"):
            result_bytes = output.read()
        else:
            logger.error(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç output –æ—Ç Replicate: {type(output)}")
            return opencv_fallback(image_bgr, mask_u8)

        out_pil = Image.open(BytesIO(result_bytes)).convert("RGB")
        out_rgb = np.array(out_pil)
        out_bgr = cv2.cvtColor(out_rgb, cv2.COLOR_RGB2BGR)

        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –≤–¥—Ä—É–≥ –∏–∑–º–µ–Ω–∏–ª–∞ —Ä–∞–∑–º–µ—Ä ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –∏—Å—Ö–æ–¥–Ω—ã–π (–∏–Ω–∞—á–µ –±—É–¥–µ—Ç –º—ã–ª–æ/—Å–∫–µ–π–ª)
        if out_bgr.shape[:2] != image_bgr.shape[:2]:
            logger.warning("‚ö†Ô∏è Replicate –∏–∑–º–µ–Ω–∏–ª —Ä–∞–∑–º–µ—Ä ‚Üí —Ä–µ—Å–∞–π–∑ –æ–±—Ä–∞—Ç–Ω–æ (LANCZOS)")
            out_bgr = cv2.resize(out_bgr, (image_bgr.shape[1], image_bgr.shape[0]), interpolation=cv2.INTER_LANCZOS4)

        # –ñ—ë—Å—Ç–∫–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å—ë –≤–Ω–µ –º–∞—Å–∫–∏ (—Ä–µ—à–∞–µ—Ç –≤–∞—à—É –ø—Ä–æ–±–ª–µ–º—É —Å ‚Äú–ª–æ–≥–æ—Ç–∏–ø–∞–º–∏ –≤—ã—à–µ –º–∞—Å–∫–∏‚Äù)
        if FORCE_PRESERVE_OUTSIDE_MASK:
            out_bgr = _composite_by_mask(image_bgr, out_bgr, mask_u8)

        logger.info("‚úÖ Replicate inpaint OK")
        return out_bgr

    except Exception as e:
        # –¢–∏–ø–æ–≤–∞—è –ø—Ä–∏—á–∏–Ω–∞ —É –≤–∞—Å: 401 Invalid token ‚Üí –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è REPLICATE_API_TOKEN –≤ Railway.
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ Replicate inpaint: {e}")
        return opencv_fallback(image_bgr, mask_u8)


def _composite_by_mask(original_bgr: np.ndarray, edited_bgr: np.ndarray, mask_u8: np.ndarray) -> np.ndarray:
    """–°–º–µ—à–∏–≤–∞–Ω–∏–µ –ø–æ –º–∞—Å–∫–µ: –±–µ—Ä—ë–º edited —Ç–æ–ª—å–∫–æ —Ç–∞–º, –≥–¥–µ mask=255; —Å–Ω–∞—Ä—É–∂–∏ ‚Äî –æ—Ä–∏–≥–∏–Ω–∞–ª."""
    m = (mask_u8.astype(np.float32) / 255.0)[:, :, None]
    out = (original_bgr.astype(np.float32) * (1.0 - m) + edited_bgr.astype(np.float32) * m)
    return np.clip(out, 0, 255).astype(np.uint8)


# –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å–æ —Å—Ç–∞—Ä—ã–º –∏–º–µ–Ω–µ–º (—á—Ç–æ–±—ã –Ω–µ –º–µ–Ω—è—Ç—å –æ—Å—Ç–∞–ª—å–Ω–æ–π –ø—Ä–æ–µ–∫—Ç)
def flux_kontext_inpaint(image: np.ndarray, mask: np.ndarray) -> np.ndarray:
    """ALI–êS: —Ä–∞–Ω—å—à–µ –±—ã–ª–æ flux-kontext-pro, —Ç–µ–ø–µ—Ä—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –º–∞—Å–æ—á–Ω—ã–π inpaint = flux-fill-pro."""
    return flux_inpaint(image, mask)


# ---------------------------------------------------------------------
# –ì—Ä–∞–¥–∏–µ–Ω—Ç (–±—ã—Å—Ç—Ä–æ, –±–µ–∑ –ø–æ–∫–∞–¥—Ä–æ–≤–æ–≥–æ putpixel)
# ---------------------------------------------------------------------
def create_gradient_layer(width: int, height: int,
                          cover_percent: int = GRADIENT_COVER_PERCENT) -> Image.Image:
    """
    –°–æ–∑–¥–∞—ë—Ç RGBA-—Å–ª–æ–π –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ –¥–ª—è –Ω–∏–∂–Ω–∏—Ö cover_percent%.
    –ù–∏–∑: alpha=255, –Ω–∏–∂–Ω—è—è –ø–æ–ª–æ–≤–∏–Ω–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ ‚Äî 100% –Ω–µ–ø—Ä–æ–∑—Ä–∞—á–Ω–∞—è,
    –≤–µ—Ä—Ö–Ω—è—è –ø–æ–ª–æ–≤–∏–Ω–∞ ‚Äî –ø–ª–∞–≤–Ω—ã–π —É—Ö–æ–¥ –≤ 0.
    """
    cover_percent = int(np.clip(cover_percent, 1, 100))
    start_row = int(height * (1 - cover_percent / 100))
    grad_h = max(1, height - start_row)

    y = np.arange(height, dtype=np.float32)
    t = (y - start_row) / float(grad_h)   # 0 –≤–≤–µ—Ä—Ö—É –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ ‚Üí 1 –≤–Ω–∏–∑—É
    t = np.clip(t, 0.0, 1.0)

    # –ù–∏–∂–Ω—è—è —á–∞—Å—Ç—å ‚Äî 100% –Ω–µ–ø—Ä–æ–∑—Ä–∞—á–Ω–∞—è
    # –ë–∞–∑–æ–≤–∞—è –≥—Ä–∞–Ω–∏—Ü–∞ (–ø–æ –¥–æ–ª–µ): –Ω–∞ –∫–∞–∫–æ–π –≤—ã—Å–æ—Ç–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è 100% —á—ë—Ä–Ω—ã–π —Å–ª–æ–π.
    base_solid_from = 1.0 - float(np.clip(GRADIENT_SOLID_FRACTION, 0.0, 1.0))
    # –ü–æ–¥–Ω–∏–º–∞–µ–º –≥—Ä–∞–Ω–∏—Ü—É –≤–≤–µ—Ä—Ö –Ω–∞ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∫–æ–ª-–≤–æ –ø–∏–∫—Å–µ–ª–µ–π (—á—Ç–æ–±—ã —Å–∫—Ä—ã—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –ø–æ–¥ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–º).
    raise_t = float(np.clip(GRADIENT_SOLID_RAISE_PX, 0, height)) / float(grad_h)
    solid_from = float(np.clip(base_solid_from - raise_t, 0.0, 1.0))

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫ —à–∫–∞–ª–µ ‚Äú–≤–µ—Ä—Ö–Ω—è—è —á–∞—Å—Ç—å –¥–æ –≥—Ä–∞–Ω–∏—Ü—ã‚Äù
    top_part = np.clip(t / max(solid_from, 1e-6), 0.0, 1.0)
    alpha = np.where(
        t >= solid_from,
        255.0,
        255.0 * (top_part ** float(GRADIENT_INTENSITY_CURVE)),
    ).astype(np.uint8)

    rgba = np.zeros((height, width, 4), dtype=np.uint8)
    rgba[:, :, 3] = alpha[:, None]  # —Ç–æ–ª—å–∫–æ –∞–ª—å—Ñ–∞, —Ü–≤–µ—Ç = —á—ë—Ä–Ω—ã–π

    logger.info(f"‚ú® –ì—Ä–∞–¥–∏–µ–Ω—Ç: cover={cover_percent}%, start_row={start_row}, solid_from={solid_from:.3f}, raise_px={GRADIENT_SOLID_RAISE_PX}")
    return Image.fromarray(rgba, mode="RGBA")


# ---------------------------------------------------------------------
# –¢–µ–∫—Å—Ç: –ø–æ–¥–±–æ—Ä —Ä–∞–∑–º–µ—Ä–∞ –∏ –æ—Ç—Ä–∏—Å–æ–≤–∫–∞ —Å–æ ‚Äústretch‚Äù
# ---------------------------------------------------------------------
def calculate_adaptive_font_size(text: str, font_path: str, max_width: int,
                                 initial_size: int, min_size: int = FONT_SIZE_MIN,
                                 stretch_width: float = TEXT_STRETCH_WIDTH) -> tuple:
    """
    –ê–≤—Ç–æ–ø–æ–¥–±–æ—Ä —Ä–∞–∑–º–µ—Ä–∞ —à—Ä–∏—Ñ—Ç–∞ –ø–æ–¥ —à–∏—Ä–∏–Ω—É —Å —É—á—ë—Ç–æ–º –±—É–¥—É—â–µ–≥–æ —Ä–∞—Å—Ç—è–∂–µ–Ω–∏—è –ø–æ —à–∏—Ä–∏–Ω–µ.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (size, font, lines)
    """
    size = int(initial_size)

    while size >= min_size:
        try:
            font = ImageFont.truetype(font_path, size)
            words = text.split()
            lines = []
            cur = []

            for w in words:
                test = " ".join(cur + [w])
                bbox = font.getbbox(test)
                w0 = bbox[2] - bbox[0]
                # –í–ê–ñ–ù–û: —É—á–∏—Ç—ã–≤–∞–µ–º –±—É–¥—É—â–∏–π stretch –ø–æ —à–∏—Ä–∏–Ω–µ
                if int(w0 * stretch_width) <= max_width:
                    cur.append(w)
                else:
                    if cur:
                        lines.append(" ".join(cur))
                        cur = [w]
                    else:
                        lines.append(w)
                        cur = []

            if cur:
                lines.append(" ".join(cur))

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ –≤–ª–µ–∑–µ—Ç –ø–æ—Å–ª–µ stretch
            fits = True
            for ln in lines:
                bbox = font.getbbox(ln)
                w0 = bbox[2] - bbox[0]
                if int(w0 * stretch_width) > max_width:
                    fits = False
                    break

            if fits:
                return size, font, lines

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —à—Ä–∏—Ñ—Ç–∞ {size}: {e}")

        size -= 2

    font = ImageFont.truetype(font_path, min_size)
    return min_size, font, [text]


def draw_text_with_stretch(base_image: Image.Image,
                           x: int, y: int,
                           text: str,
                           font: ImageFont.FreeTypeFont,
                           fill_color: tuple,
                           outline_color: tuple,
                           stretch_width: float = TEXT_STRETCH_WIDTH,
                           stretch_height: float = TEXT_STRETCH_HEIGHT,
                           shadow_offset: int = TEXT_SHADOW_OFFSET) -> int:
    """
    –†–∏—Å—É–µ—Ç —Ç–µ–∫—Å—Ç —Å —Ç–µ–Ω—å—é+–æ–±–≤–æ–¥–∫–æ–π, –∑–∞—Ç–µ–º —Ä–∞—Å—Ç—è–≥–∏–≤–∞–µ—Ç –æ–±—â–∏–π ‚Äú—Å–ª–æ–π —Ç–µ–∫—Å—Ç–∞‚Äù.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—É—é –≤—ã—Å–æ—Ç—É –Ω–∞—Ä–∏—Å–æ–≤–∞–Ω–Ω–æ–≥–æ (–ø–æ—Å–ª–µ stretch).
    """
    bbox = font.getbbox(text)
    tw = bbox[2] - bbox[0]
    th = bbox[3] - bbox[1]

    # –ó–∞–ø–∞—Å –ø–æ —Ä–∞–∑–º–µ—Ä—É, —á—Ç–æ–±—ã –Ω–µ –æ–±—Ä–µ–∑–∞—Ç—å —Ç–µ–Ω—å/–æ–±–≤–æ–¥–∫—É
    pad = max(6, shadow_offset + TEXT_OUTLINE_THICKNESS * 2)
    temp_w = int(tw * (stretch_width + 1.0)) + pad * 2
    temp_h = int(th * (stretch_height + 1.0)) + pad * 2

    temp = Image.new("RGBA", (temp_w, temp_h), (0, 0, 0, 0))
    d = ImageDraw.Draw(temp)

    # –†–∏—Å—É–µ–º –±–ª–∏–∂–µ –∫ –ª–µ–≤–æ–º—É/–≤–µ—Ä—Ö–Ω–µ–º—É —Å –ø–∞–¥–¥–∏–Ω–≥–æ–º
    tx, ty = pad, pad

    # –¢–µ–Ω—å
    d.text((tx + shadow_offset, ty + shadow_offset), text, font=font, fill=(0, 0, 0, 128))

    # –û–±–≤–æ–¥–∫–∞
    for t in range(int(TEXT_OUTLINE_THICKNESS)):
        r = t + 1
        for dx, dy in [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]:
            d.text((tx + dx * r, ty + dy * r), text, font=font, fill=outline_color)

    # –û—Å–Ω–æ–≤–Ω–æ–π
    d.text((tx, ty), text, font=font, fill=fill_color)

    # –û–±—Ä–µ–∑–∞–µ–º –ø–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É
    bb = temp.getbbox()
    if not bb:
        return th

    crop = temp.crop(bb)

    # –†–∞—Å—Ç—è–≥–∏–≤–∞–µ–º
    sw = max(1, int(crop.width * stretch_width))
    sh = max(1, int(crop.height * stretch_height))
    crop = crop.resize((sw, sh), Image.Resampling.LANCZOS)

    # –ü–æ–∑–∏—Ü–∏—è: x,y —Å—á–∏—Ç–∞—é—Ç—Å—è –∫–∞–∫ ‚Äú–≤–µ—Ä—Ö–Ω–∏–π –ª–µ–≤—ã–π‚Äù –ø—Ä–∏–º–µ—Ä–Ω–æ –ø–æ–¥ —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–æ–∫
    base_image.paste(crop, (x, y), crop)
    return sh


# ---------------------------------------------------------------------
# –†–ï–ù–î–ï–†–´ –†–ï–ñ–ò–ú–û–í
# ---------------------------------------------------------------------
def render_mode1_logo(image: Image.Image, title_translated: str) -> Image.Image:
    """–†–µ–∂–∏–º 1: –õ–æ–≥–æ + –ª–∏–Ω–∏–∏ + –∑–∞–≥–æ–ª–æ–≤–æ–∫ (UPPERCASE)."""
    image = image.convert("RGBA")
    draw = ImageDraw.Draw(image, "RGBA")
    width, height = image.size
    max_text_width = int(width * TEXT_WIDTH_PERCENT)

    title = (title_translated or "").upper()

    _, title_font, title_lines = calculate_adaptive_font_size(
        title, FONT_PATH, max_text_width, FONT_SIZE_MODE1, stretch_width=TEXT_STRETCH_WIDTH
    )

    # –≤—ã—Å–æ—Ç–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ (–ø–æ—Å–ª–µ stretch)
    title_heights = []
    for ln in title_lines:
        bb = title_font.getbbox(ln)
        title_heights.append(int((bb[3] - bb[1]) * TEXT_STRETCH_HEIGHT))
    total_title_h = sum(title_heights) + max(0, (len(title_lines) - 1) * LINE_SPACING)

    # –õ–æ–≥–æ
    logo_font = ImageFont.truetype(FONT_PATH, FONT_SIZE_LOGO)
    logo_text = "@neurostep.media"
    bb = logo_font.getbbox(logo_text)
    logo_w = bb[2] - bb[0]
    logo_h = bb[3] - bb[1]

    total_h = logo_h + SPACING_LOGO_TO_TITLE + total_title_h
    start_y = height - SPACING_BOTTOM - total_h

    # –õ–æ–≥–æ –ø–æ–∑–∏—Ü–∏—è
    logo_x = (width - logo_w) // 2
    logo_y = start_y

    # –õ–∏–Ω–∏–∏ –ø–æ —Ü–µ–Ω—Ç—Ä—É –ª–æ–≥–æ
    line_y = logo_y + logo_h // 2
    line_left_start = logo_x - LOGO_LINE_LENGTH - 10
    line_right_start = logo_x + logo_w + 10

    draw.line([(line_left_start, line_y), (line_left_start + LOGO_LINE_LENGTH, line_y)], fill=COLOR_TURQUOISE, width=LOGO_LINE_THICKNESS_PX)
    draw.line([(line_right_start, line_y), (line_right_start + LOGO_LINE_LENGTH, line_y)], fill=COLOR_TURQUOISE, width=LOGO_LINE_THICKNESS_PX)

    draw.text((logo_x, logo_y), logo_text, font=logo_font, fill=COLOR_WHITE)

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    cur_y = start_y + logo_h + SPACING_LOGO_TO_TITLE
    for ln in title_lines:
        bb = title_font.getbbox(ln)
        ln_w = bb[2] - bb[0]
        x = (width - int(ln_w * TEXT_STRETCH_WIDTH)) // 2
        h_drawn = draw_text_with_stretch(image, x, cur_y, ln, title_font, COLOR_TURQUOISE, COLOR_OUTLINE)
        cur_y += h_drawn + LINE_SPACING

    return image


def render_mode2_text(image: Image.Image, title_translated: str) -> Image.Image:
    """–†–µ–∂–∏–º 2: —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ (UPPERCASE)."""
    image = image.convert("RGBA")
    width, height = image.size
    max_text_width = int(width * TEXT_WIDTH_PERCENT)

    title = (title_translated or "").upper()

    _, title_font, title_lines = calculate_adaptive_font_size(
        title, FONT_PATH, max_text_width, FONT_SIZE_MODE2, stretch_width=TEXT_STRETCH_WIDTH
    )

    title_heights = []
    for ln in title_lines:
        bb = title_font.getbbox(ln)
        title_heights.append(int((bb[3] - bb[1]) * TEXT_STRETCH_HEIGHT))
    total_h = sum(title_heights) + max(0, (len(title_lines) - 1) * LINE_SPACING)

    start_y = height - SPACING_BOTTOM - total_h

    cur_y = start_y
    for ln in title_lines:
        bb = title_font.getbbox(ln)
        ln_w = bb[2] - bb[0]
        x = (width - int(ln_w * TEXT_STRETCH_WIDTH)) // 2
        h_drawn = draw_text_with_stretch(image, x, cur_y, ln, title_font, COLOR_TURQUOISE, COLOR_OUTLINE)
        cur_y += h_drawn + LINE_SPACING

    return image


def render_mode3_content(image: Image.Image, title_translated: str, subtitle_translated: str) -> Image.Image:
    """–†–µ–∂–∏–º 3: –∑–∞–≥–æ–ª–æ–≤–æ–∫ + –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫ (–æ–±–∞ UPPERCASE)."""
    image = image.convert("RGBA")
    width, height = image.size
    max_text_width = int(width * TEXT_WIDTH_PERCENT)

    title = (title_translated or "").upper()
    subtitle = (subtitle_translated or "").upper()

    title_size, title_font, title_lines = calculate_adaptive_font_size(
        title, FONT_PATH, max_text_width, FONT_SIZE_MODE3_TITLE, stretch_width=TEXT_STRETCH_WIDTH
    )

    subtitle_initial = int(title_size * 0.80)
    _, subtitle_font, subtitle_lines = calculate_adaptive_font_size(
        subtitle, FONT_PATH, max_text_width, subtitle_initial, stretch_width=TEXT_STRETCH_WIDTH
    )

    title_heights = []
    for ln in title_lines:
        bb = title_font.getbbox(ln)
        title_heights.append(int((bb[3] - bb[1]) * TEXT_STRETCH_HEIGHT))
    sub_heights = []
    for ln in subtitle_lines:
        bb = subtitle_font.getbbox(ln)
        sub_heights.append(int((bb[3] - bb[1]) * TEXT_STRETCH_HEIGHT))

    total_title_h = sum(title_heights) + max(0, (len(title_lines) - 1) * LINE_SPACING)
    total_sub_h = sum(sub_heights) + max(0, (len(subtitle_lines) - 1) * LINE_SPACING)

    total_h = total_title_h + SPACING_TITLE_TO_SUBTITLE + total_sub_h
    start_y = height - SPACING_BOTTOM - total_h

    cur_y = start_y
    for ln in title_lines:
        bb = title_font.getbbox(ln)
        ln_w = bb[2] - bb[0]
        x = (width - int(ln_w * TEXT_STRETCH_WIDTH)) // 2
        h_drawn = draw_text_with_stretch(image, x, cur_y, ln, title_font, COLOR_TURQUOISE, COLOR_OUTLINE)
        cur_y += h_drawn + LINE_SPACING

    cur_y += SPACING_TITLE_TO_SUBTITLE

    for ln in subtitle_lines:
        bb = subtitle_font.getbbox(ln)
        ln_w = bb[2] - bb[0]
        x = (width - int(ln_w * TEXT_STRETCH_WIDTH)) // 2
        h_drawn = draw_text_with_stretch(image, x, cur_y, ln, subtitle_font, COLOR_WHITE, COLOR_OUTLINE)
        cur_y += h_drawn + LINE_SPACING

    return image


# ---------------------------------------------------------------------
# –û–°–ù–û–í–ù–û–ô WORKFLOW
# ---------------------------------------------------------------------
def process_full_workflow(image_bgr: np.ndarray, mode: int) -> tuple:
    """
    –ü–æ–ª–Ω—ã–π workflow –¥–ª—è —Ä–µ–∂–∏–º–æ–≤ 1,2,3.

    –†–µ–∂–∏–º—ã:
    1 ‚Äî –ª–æ–≥–æ + –∑–∞–≥–æ–ª–æ–≤–æ–∫
    2 ‚Äî —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫
    3 ‚Äî –∑–∞–≥–æ–ª–æ–≤–æ–∫ + –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫
    """
    logger.info("=" * 60)
    logger.info(f"üöÄ –ü–û–õ–ù–´–ô WORKFLOW - –†–ï–ñ–ò–ú {mode}")
    logger.info("=" * 60)

    h, w = image_bgr.shape[:2]

    # –®–ê–ì 1: OCR
    logger.info("üìã –®–ê–ì 1: OCR (Google Vision)")
    ocr = google_vision_ocr(image_bgr, crop_bottom_percent=OCR_BOTTOM_PERCENT)
    if not ocr["text"]:
        logger.warning("‚ö†Ô∏è –¢–µ–∫—Å—Ç –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω")
        return image_bgr, ocr

    # –®–ê–ì 2: –ú–∞—Å–∫–∞ –Ω–∏–∂–Ω–∏—Ö N%
    logger.info("üìã –®–ê–ì 2: –ú–∞—Å–∫–∞ (–Ω–∏–∂–Ω–∏–µ %)")
    mask = np.zeros((h, w), dtype=np.uint8)
    mask_start = int(h * (1 - MASK_BOTTOM_PERCENT / 100))
    mask[mask_start:, :] = 255
    logger.info(f"üìê –ú–∞—Å–∫–∞: —Å—Ç—Ä–æ–∫–∏ {mask_start}-{h} (–Ω–∏–∂–Ω–∏–µ {MASK_BOTTOM_PERCENT}%)")

    # –®–ê–ì 3: Inpaint (Replicate ‚Üí FLUX Fill)
    logger.info("üìã –®–ê–ì 3: Inpaint (Replicate FLUX Fill)")
    clean_bgr = flux_inpaint(image_bgr, mask)

    # –®–ê–ì 4: –ü–µ—Ä–µ–≤–æ–¥
    logger.info("üìã –®–ê–ì 4: –ü–µ—Ä–µ–≤–æ–¥ (OpenAI)")
    title_translated, subtitle_translated = "", ""

    if mode == 3:
        lines = ocr["lines"]
        if len(lines) >= 2:
            title = " ".join(lines[:-1])
            subtitle = lines[-1]
        else:
            title, subtitle = ocr["text"], ""

        title_translated = openai_translate(title)
        subtitle_translated = openai_translate(subtitle) if subtitle else ""
    else:
        title_translated = openai_translate(ocr["text"])

    # –®–ê–ì 5: –ì—Ä–∞–¥–∏–µ–Ω—Ç (—Ç–æ—á–Ω–æ –Ω–∞ –Ω–∏–∂–Ω–∏–µ N%)
    logger.info("üìã –®–ê–ì 5: –ì—Ä–∞–¥–∏–µ–Ω—Ç")
    clean_rgb = cv2.cvtColor(clean_bgr, cv2.COLOR_BGR2RGB)
    pil = Image.fromarray(clean_rgb).convert("RGBA")

    grad = create_gradient_layer(pil.size[0], pil.size[1], cover_percent=GRADIENT_COVER_PERCENT)
    pil = Image.alpha_composite(pil, grad)
    logger.info("‚úÖ –ì—Ä–∞–¥–∏–µ–Ω—Ç –Ω–∞–ª–æ–∂–µ–Ω")

    # –®–ê–ì 6: –¢–µ–∫—Å—Ç/–ª–æ–≥–æ –ø–æ —Ä–µ–∂–∏–º–∞–º
    logger.info("üìã –®–ê–ì 6: –†–µ–Ω–¥–µ—Ä —Ç–µ–∫—Å—Ç–∞")
    if mode == 1:
        pil = render_mode1_logo(pil, title_translated)
    elif mode == 2:
        pil = render_mode2_text(pil, title_translated)
    elif mode == 3:
        pil = render_mode3_content(pil, title_translated, subtitle_translated)
    else:
        logger.warning(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º {mode} ‚Üí –ø—Ä–æ–ø—É—Å–∫–∞—é —Ä–µ–Ω–¥–µ—Ä")

    out_rgb = np.array(pil.convert("RGB"))
    out_bgr = cv2.cvtColor(out_rgb, cv2.COLOR_RGB2BGR)

    logger.info("=" * 60)
    logger.info("‚úÖ WORKFLOW –ó–ê–í–ï–†–®–Å–ù!")
    logger.info("=" * 60)
    return out_bgr, ocr


# –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å (–≤ –ø—Ä–æ–µ–∫—Ç–µ –º–æ–∂–µ—Ç –≥–¥–µ-—Ç–æ –≤—ã–∑—ã–≤–∞—Ç—å—Å—è —Å—Ç–∞—Ä–æ–µ –∏–º—è)
def replicate_inpaint(image: np.ndarray, mask: np.ndarray) -> np.ndarray:
    """–ê–ª–∏–∞—Å –¥–ª—è inpaint."""
    return flux_inpaint(image, mask)
